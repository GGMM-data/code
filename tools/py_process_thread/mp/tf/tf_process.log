WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.699127 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.700997 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.703000 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.705166 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.708273 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.711859: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.712273 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.714070: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.716139: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.716512: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.716554: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.716563: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.716666: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.716699: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.716705: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.717237: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.717768 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.718295: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.718835: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.718864: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.718871: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.718946: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.718975: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.718981: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.719404: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.721140: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.721184: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.721192: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.721267: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.721294: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.721300: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.721851: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.722448: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.722572 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.723723: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.723766: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.723777: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.723898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.723936: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.723946: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.724571: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.724924: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.725014: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.725281: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.725300: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.725353: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.725366: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.727436: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.727516: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.727529: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.727706: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.727750: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.727760: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.728612: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.729164: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.729708: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.728794 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.729736: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.730674: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.732714: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.732715: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.732844: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.733367: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.733389: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.735758: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.735833: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.735846: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.735985: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.736030: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.736039: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.736613: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.738462: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.738737: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.738250 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.739023: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.739045: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.739383: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.740147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.742923: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.744889: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.744942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.745238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.745255: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.746033: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.746379: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.746425: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.746435: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.746546: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.746586: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.746596: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.746269 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.746948: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.746979: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.746989: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.747069: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.747101: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.747110: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.747192: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.747562: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.749683: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.749748: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.749768: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.749895: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.749933: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.749939: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.750445: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.750597 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.751421: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.753980 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.756007: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.756951: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.756951: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.757186: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.757292: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.757307: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.757300: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.757319: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.757581: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.757599: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.758942 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.760354: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.760422: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.760430: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.760610: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.760657: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.760664: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.761349: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.763721: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.763721: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.763868: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.766725: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.767628: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.768028: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.768052: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.768106: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.768331: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.768364: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.768373: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.768456: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.768486: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.768494: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.769099: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.768650 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.770933: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.772274: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.772330: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.772341: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.772479: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.772516: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.772539: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.773173: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.773580 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.775781: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.776042: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.776089: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.776098: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.776240: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.776283: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.776290: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.776966: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.777172: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.777620: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.777645: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.777971: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.778446 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.780043: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.780471: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.780492: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.781630: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.781671: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.781681: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.781814: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.781853: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.781863: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.782394: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.784129: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.784485 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.787143: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.787713: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.788570: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.789026: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.789049: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.789835: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.790613 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.792500: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.792560: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.792572: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.792720: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.792771: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.792783: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.792795: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.793104: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.793121: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.793385: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.795042: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.795111: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.795123: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.795273: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.795331: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.795358: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.795630: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.795430 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.796107: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.796131: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.799221: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.799628: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.800544: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.800583: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.800594: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.800682: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.800717: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.800726: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.801260: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.802300: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.802474: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.802600: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.802616: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.802835: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.802855: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.802401 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.803738: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.803782: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.803806: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.803955: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.803997: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.804007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.804664: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.809036: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.809704: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.809704: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.810183: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.811032: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.811428: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.811498: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.811514: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.811793: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.811813: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.812150 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.812963 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.816312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.816390: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.816401: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.816512: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.816559: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.816568: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.817068: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.817737: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.817775: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.817785: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.817902: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.817938: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.817946: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.818472: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.818653: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.820137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.821207 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.822498: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.822874: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.822934: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.822952: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.824636: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.824692: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.824703: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.824848: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.824890: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.824899: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.825451: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.827104 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.828472: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.829010: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.829464: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.829483: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.830270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.830280: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.834061 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.834742: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.835218: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.836237: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.836265: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.836272: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.836339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.836363: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.836369: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.836535: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.836561: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.836569: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.836632: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.836660: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.836667: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.836768: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.837072: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.837301: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.837782: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.837800: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.838925: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.838973: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.838979: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.839097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.839136: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.839142: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.838718 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.839785: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.842178: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.844909: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.844905: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.845099: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.845256: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.845272: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.845287: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.845304: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.845709: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.846079: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.846097: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.845939 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.847141: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.847185: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.847199: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.847359: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.847415: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.847425: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.848106: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.849540: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.850657 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.851527: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.852870: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.854414: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.854493: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.854507: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.854660: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.854703: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.854714: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.855296: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.856318: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.856780: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.857124: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.857569: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.857596: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.858658 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.860038: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.860086: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.860096: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.860216: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.860265: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.860272: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.860768: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.862179 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.864435: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.864889: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.867438: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.867716: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.867736: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.867751: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.868657: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.868687: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.868694: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.868785: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.868813: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.868821: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.869045: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.869458: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.869483: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.869509: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.870379 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.871868: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.871934: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.871948: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.872083: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.872140: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.872151: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.872905: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.872920: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.874287: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.877014: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.877148: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.877450: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.877490: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.877502: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.877624: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.877064 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.877665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.877677: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.878362: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.880365: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.880681: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.880723: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.880735: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.880873: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.880872: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.880891: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.880887: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.880904: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.880911: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.881210: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.881246: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.881535: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.882204 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.883347 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.887666: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.887666: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.888980: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.889127: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.889408: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.889430: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.889601: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.889992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.890011: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.890500 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.893893: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.893987: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.894001: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.894199: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.894256: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.894266: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.894186 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.894983: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.896866: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.896889: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.897567: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.900945: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.900964: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.902012 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.902952: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.902993: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.903003: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.903107: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.903140: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.903148: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.903673: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.906602: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.906602: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.906669: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.906669: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.906679: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.906682: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.906199 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.906780: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.906781: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.906822: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.906824: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.906829: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.906835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.907022: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.907498: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.907519: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.907626: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.907626: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.908067: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.908068: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.912736: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.913211: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.913241: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.913467: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.913835: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.913858: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.914236: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.914755: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.914794: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.914802: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.914956: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.914997: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.915004: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.915186: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.915226: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.915237: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.915376: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.914701 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.915419: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.915448: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.915675: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.916179: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.917449: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.917967 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.920938: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.920963: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.921028: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.921279: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.921295: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.921859: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.921892: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.921902: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.922009: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.922043: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.922052: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.922604: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.924260: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.925423: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.925818: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.925838: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.927683: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.928085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.928110: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.928866: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.928865: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.928932: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.928977: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.928987: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.929155: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.929201: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.929211: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.929293: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.929316: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.930143: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.929140 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.931828 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.933685: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.935355: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.935954: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.937084: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.937396: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.938969: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.939023: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.939036: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.939126: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.939160: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.939170: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.939682: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.940670: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.940695: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.940702: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.940815: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.940850: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.940859: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.941321: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.942128 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.942128 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.944959: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.945278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.945295: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.946053: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.946325: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.946341: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.949058: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.948875 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.949620: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.949648: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.950075: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.950075: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.952781: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.952781: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.956183: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.956242: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.956255: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.956268: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.956266: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.956277: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.956390: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.956390: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.956427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.956427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.956416: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.956436: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.956437: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.957064: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.957158: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.958429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.958429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.958557 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.961175 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.963559: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.963559: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.963619: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.963623: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.963628: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.963632: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.963730: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.963730: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.963765: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.963765: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.963771: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.963773: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.964405: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.964433: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.964433: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.964503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.964835: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.965006: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.965021: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.965207: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.965229: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.964832 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.969214: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.969300: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.969315: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.969490: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.969546: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.969558: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.970195: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.970751: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.971296: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.971325: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.971688: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.972138: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.973360 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.976313 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.977310: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.977436: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.977798: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.977820: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.978894: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.981115: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.981552: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.981576: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.981985: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.982315: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.982356: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.982368: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.982470: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.982508: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.982518: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.983117: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.984172: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.985664: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.986345: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.986400: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.986415: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.986710: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.986754: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.986766: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.986507 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.987465: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.988555: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:13.989455: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.989507: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.989518: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.989695: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.989750: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.989760: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.989220 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.990508: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:13.992294: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.992343: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:13.992681: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.992698: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.994151: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:13.996159 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:13.996993: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.997013: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:13.997440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.997465: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.997589: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:13.997607: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:13.998550: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:13.998593: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:13.998607: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:13.998748: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:13.998795: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:13.998806: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:13.999438: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.000601: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.000650: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.000658: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.000846: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.000894: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.000904: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.001024: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.001516: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.001089 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.004009: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.005182: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.005264: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.006806: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.007154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.007174: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.008220: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.008671: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.008695: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.008867 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.010869: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.010899: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.010935: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.010949: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.011099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.011136: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.011143: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.011673: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.014564: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.014564: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.014929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.014512 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.018556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.019398: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.019765: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.019787: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.020637 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.024340: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.025543: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.027708: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.030191 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.030087 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.032724: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.033671 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.036304: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.036345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.036352: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.036436: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.036464: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.036471: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.036239 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.036902: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.038406: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.038442: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.038453: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.038541: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.038581: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.038592: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.039010: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.040171: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.040208: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.040218: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.040344: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.040376: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.040385: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.041006: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.041748 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.043788: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.044202: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.044220: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.047500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.047840: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.047890: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.047898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.048000: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.048015: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.048050: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.048056: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.048457: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.048481: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.048782: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.049481: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.050384: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.050386: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.050869: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.050911: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.051032 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.052724: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.055582: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.055660: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.055674: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.055042 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.055826: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.055880: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.055891: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.056601: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.056916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.057149: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.057444: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.061045: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.061160: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.061190: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.061242: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.061257: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.061514: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.061536: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.061556: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.061607: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.061614: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.061829: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.061860: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.061867: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.061940: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.061967: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.061973: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.062619: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.062619: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.062952 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.065009: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.065491: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.065520: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.065650: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.065699: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.065711: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.065871: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.065914: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.065925: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.066565: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.067668: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.067718: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.067727: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.067882: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.067924: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.067930: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.068501: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.069528: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.070142: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.072398: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.073400: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.073788: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.073878: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.073933: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.073954: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.074318: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.074337: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.074949: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.074595 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.075344: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.075366: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.076190 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.078317: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.078621: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.078647: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.079043: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.079093: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.079104: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.079717: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.081128: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.081348: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.081362: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.081630: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.081681: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.081693: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.081903: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.081956: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.081966: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.082717: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.082181 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.083244: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.083271: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.083278: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.083333: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.083382: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.083412: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.083418: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.083816: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.085823: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.085872: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.085879: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.085984: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.086012: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.086018: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.086501: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.087362: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.087787: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.087809: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.088275: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.088313: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.088321: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.088441: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.088474: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.088483: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.088946: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.089117: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.089330: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.089352: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.090964 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.092621: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.092860: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.093238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.093270: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.093363: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.093388: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.093958: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.095141: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.095777: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.096364: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.097258: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.097293: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.097682: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.098700 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.100206: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.101391: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.101423: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.101470: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.101483: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.101690: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.101766: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.101776: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.102199: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.102238: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.102248: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.102342: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.102379: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.102388: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.102462: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.102991: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.105506: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.105579: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.105793: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.105942: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.105964: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.106384: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.106429: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.106439: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.106571: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.106614: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.106624: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.107174: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.107507 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.110581: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.112602: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.113075: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.113079: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.113406: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.113426: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.113490: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.113510: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.114392: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.114426: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.114433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.114534: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.114567: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.114574: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.114996: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.115114: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.114833 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.118567: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.118933: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.119015: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.119035: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.119493: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.119691: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.119739: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.119750: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.119909: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.119954: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.119964: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.120537: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.120409 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.123672: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.123988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.124011: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.124842: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.125215: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.126281 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.129237: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.129286: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.129298: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.129342: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.129392: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.129427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.129437: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.129456: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.129819: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.129841: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.130077: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.130856: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.131345 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.134916: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.134980: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.134988: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.135127: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.135159: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.135165: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.135664: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.135918: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.136596: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.138298 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.140360: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.140428: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.140437: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.140517: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.140540: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.140572: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.140578: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.140921: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.140919: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.140963: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.140977: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.141225: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.141223: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.141242: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.142465 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.145407: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.145530: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.145547: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.145723: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.145788: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.145800: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.146636: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.147302: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.147713: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.147712: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.149671 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.150812: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.150847: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.150854: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.150939: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.150966: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.150973: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.151390: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.151761: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.152064: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.152078: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.152104: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.152357: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.152373: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.154573: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.157472: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.157718: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.158362 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.158931: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.158968: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.158976: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.159084: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.159118: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.159125: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.159581: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.160455: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.162077 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.164279: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.164324: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.164333: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.164403: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.164424: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.164451: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.164457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.164685: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.164698: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.164952: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.165009: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.165358: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.165376: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.165779: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.166646 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.170123: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.170189: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.170197: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.170320: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.170355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.170361: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.170554: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.170564: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.170831: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.172432: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.174167 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.176503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.176671: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.176706: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.176717: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.176837: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.176857: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.176875: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.176874: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.176885: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.177549: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.177573: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.178205 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.179905: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.180170: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.180187: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.182101: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.182166: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.182179: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.182326: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.182371: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.182382: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.182983: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.184993: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.186077: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.185907 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.187663: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.188963: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.189328: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.189350: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.190114: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.190145: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.190152: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.190259: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.190287: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.190293: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.191198: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.192963: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.193374: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.193395: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.194853: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.194468 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.195762: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.195782: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.198135 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.199773: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.200546: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.200969: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.200991: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.201801: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.201842: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.201854: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.201529 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.201999: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.202043: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.202051: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.202175: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.202205: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.202214: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.202322: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.202354: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.202364: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.202692: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.202851: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.203760: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.206350 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.207894: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.208620: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.208667: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.208690: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.208859: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.208907: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.208916: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.209571: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.210821: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.210879: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.211239: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.211258: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.211257: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.211277: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.212653 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.213991: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.216766: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.217046: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.217871: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.218133: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.218134: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.218261: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.218279: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.219653 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.221141: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.221203: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.221214: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.221364: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.221404: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.221414: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.221921: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.222858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.223940: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.224629: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.224675: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.224686: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.224836: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.224875: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.224882: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.225118: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.225152: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.225174: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.225278: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.225325: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.225337: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.225451: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.225948: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.225547 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.228271: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.228348: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.228362: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.228494: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.228536: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.228545: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.229134: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.231444: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.231795: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.231817: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.231922: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.232275: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.232595: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.232615: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.235092: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.235637: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.235663: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.235732: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.236177: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.236201: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.236626: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.236684: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.236698: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.236871: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.236926: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.236937: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.237451: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.237664: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.238608: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.237896 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.239695: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.241798: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.241865: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.241875: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.242016: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.242055: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.242062: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.242593: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.242080 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.243270: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.243271: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.244556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.247660: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.247974: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.247995: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.248535: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.248573: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.248583: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.248698: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.248749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.248760: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.248920: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.249299: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.249319: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.249321: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.249296 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.251807: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.253351 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.255071: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.256075: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.256120: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.256129: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.256220: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.256254: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.256260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.256563: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.256681: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.256880: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.256942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.257236: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.257249: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.261018: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.261080: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.261089: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.261212: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.261250: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.261258: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.261674: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.261384 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.262397: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.262978: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.263464: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.263480: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.264603 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.266449: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.269652: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.269748: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.270021: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.270042: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.270663: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.270709: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.270718: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.270808: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.270842: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.270850: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.271435: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.271451: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.271780 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.274475: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.274527: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.274535: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.274656: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.274687: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.274693: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.275155: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.276599: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.276703: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.279454: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.280778: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.280820: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.280831: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.280917: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.280950: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.280958: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.280568 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.280975: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.281320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.281337: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.281465: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.282810: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.283227: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.283241: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.283263: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.283265: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.283274: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.283407: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.283441: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.283448: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.284018: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.284360 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.287182: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.289271: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.289888: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.292571: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.292790: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.293078: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.293098: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.293109: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.293193: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.293210: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.293567: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.293599: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.293610: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.293708: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.293743: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.293752: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.294330: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.293882 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.297504: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.297586: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.297594: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.297749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.297803: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.297810: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.298393: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.297808 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.299119: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.299119: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.299584: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.300877: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.301121: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.301136: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.303466: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.303509: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.303516: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.303631: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.303640: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.303666: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.303673: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.303962: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.303982: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.304282: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.304284 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.306948: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.310635: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.311605: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.312036 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.312954: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.313296: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.313315: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.315131: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.315184: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.315191: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.315321: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.315354: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.315361: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.315909: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.315481 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.316798: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.318481: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.321269: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.321326: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.321337: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.321427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.321465: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.321474: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.322135: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.322360: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.322095 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.324017: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.324519: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.324539: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.325652: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.326462: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.326502: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.326513: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.326623: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.326661: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.326670: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.327302: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.327879 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.329005: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.329046: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.329054: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.329181: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.329218: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.329225: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.329700: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.330410: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.330794: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.330813: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.331209: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.332584: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.334262: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.334530: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.334582: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.334598: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.334928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.334944: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.337611: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.337703: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.337716: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.337827: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.337868: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.337875: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.337913: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.338002: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.338423: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.337892 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.341250: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.341250: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.341832: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.341888: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.341902: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.342056: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.342106: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.342135: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.342694: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.343031: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.343131 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.345227: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.345599: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.345615: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.346519: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.346548: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.346555: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.346650: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.346678: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.346685: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.347164: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.347040 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.349076: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.349516: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.349536: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.353008: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.355200: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.355445: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.357572: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.357870: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.358205: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.358228: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.358998: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.359027: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.359035: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.359111: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.359136: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.359142: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.359625: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.359411 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.359412 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.361807: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.361858: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.361864: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.361941: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.361972: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.361978: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.362451: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.362776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.363657: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.364903: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.365158: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.365172: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.366056 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.366772: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.366807: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.366823: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.366933: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.366965: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.366972: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.367444: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.370160: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.373038: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.373038: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.373579: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.373601: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.373612: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.373631: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.373930: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.374448: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.374413 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.378461 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.379126: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.379512: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.380021: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.380074: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.380086: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.380308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.380358: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.380366: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.380526: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.380559: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.380568: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.380667: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.380697: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.380705: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.380942: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.381163: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.381722: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.384361 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.385208: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.385263: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.385270: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.385394: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.385430: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.385437: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.385914: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.386044: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.386389: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.386405: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.390796 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.391897: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.392614: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.393047: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.393465: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.393486: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.395926: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.395985: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.395997: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.396104: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.396143: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.396154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.396781: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.397024: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.397098: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.397369: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.397390: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.398221 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.398922: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.400351: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.401183: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.401218: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.401226: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.401306: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.401339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.401345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.401793: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.402480: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.404093: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.404527: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.404550: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.404537 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.407305: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.409045: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.409422: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.409441: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.409920 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.411274: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.412980 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.413928: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.415778: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.417670: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.418076 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.421952: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.422023 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.424469: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.425938 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.427675: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.427710: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.427725: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.427808: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.427834: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.427841: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.428269: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.429561: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.431276 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.434559: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.434637: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.434652: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.434674: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.434782: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.434821: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.434831: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.435350: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.435451: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.435235 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.435800: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.435818: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.438107: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.438151: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.438157: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.438256: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.438284: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.438290: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.438710: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.440412: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.442110: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.443079: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.443117: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.443128: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.443217: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.443250: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.443260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.443729: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.445094: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.445306: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.445480: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.445505: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.445730: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.445752: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.446083: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.446126: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.446137: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.446294: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.446338: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.446349: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.446912: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.446943: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.446951: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.447106: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.447146: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.447153: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.447204: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.446671 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.447765: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.447218 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.450456: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.450981: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.451445: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.451469: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.453945: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.452899: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.455184: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.455391: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.455571: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.455589: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.455864: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.455883: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.456013: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.456055: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.456067: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.456227: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.456269: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.456280: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.456854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.456061: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.456429 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.458814: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.462365: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.462365: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.464248: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.464654: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.464677: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.465109: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.465117: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.465853: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.465881: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.465887: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.465954: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.465983: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.465990: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.466662: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.466283 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.467839 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.470751: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.473056: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.473495: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.473563: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.473596: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.474551 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.475432: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.475486: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.475496: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.475626: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.475661: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.475668: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.476012: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.476055: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.476069: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.476187: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.476231: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.476244: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.476312: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.476735: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.478320: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.478383: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.478396: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.478530: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.478568: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.478577: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.479095: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.480408: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.481863: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.481927: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.481949: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.482051: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.482074: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.482090: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.482100: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.482103: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.482112: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.482179: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.482209: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.482217: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.482271: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.482737: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.482737: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.483316: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.483351: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.483362: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.483449: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.483483: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.483492: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.484019: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.484667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.485143: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.485369: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.485507: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.485527: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.486442: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.486933: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.486968: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.488106: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.488167: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.487451 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.488198: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.487601 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.488382: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.488429: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.488440: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.489205: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.490560: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.490619: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.490632: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.490769: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.490814: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.490824: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.491410: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.492610: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.492925: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.492959: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.493032: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.493047: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.493518: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.493534: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.493679: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.493700: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.494029: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.494387: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.499114: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.499114: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.499164: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.499214: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.499226: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.499346: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.499386: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.499434: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.499446: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.499195 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.500247: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.501006: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.501037: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.501329: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.501345: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.501370: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.501389: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.504994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.505056: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.505234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.505514: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.505547: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.506256: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.506588: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.506605: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.507373: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.507988: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.507983 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.511564: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.511623: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.511631: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.511627: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.511708: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.511753: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.511760: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.511779: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.511792: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.511789: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.511799: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.511869: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.511904: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.511926: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.512207: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.512386: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.514365 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.516626: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.519438: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.519662: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.519727: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.519743: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.519964: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.519978: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.519991: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.519993: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.519999: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.520007: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.520077: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.520114: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.520124: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.520578: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.521293 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.524767: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.524830: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.524842: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.524944: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.524989: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.525001: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.525001: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.525288: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.525508: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.529074: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.529412: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.529430: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.529956 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.530662: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.531024: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.531046: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.532012: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.532473 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.535939: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.535945: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.536484: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.536526: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.536537: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.536646: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.536690: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.536701: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.537126: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.537143: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.540847 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.541648: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.541696: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.541705: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.541807: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.541820: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.541857: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.541866: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.542113: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.542129: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.542441: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.544982 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.547945: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.549036: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.549265: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.552762: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.552966: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.553428: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.553444: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.554096 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.554960: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.554999: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.555007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.555145: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.555185: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.555203: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.555778: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.555833: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.555879: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.555890: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.556047: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.556092: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.556103: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.556736: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.556766 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.559674: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.560593: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.562756: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.562799: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.562809: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.562896: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.562926: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.562934: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.563363: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.564514: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.564543: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.564553: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.564648: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.564679: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.564687: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.564972: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.564971: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.565328: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.565332: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.565357: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.565429: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.565452: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.566295 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.569518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.570593 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.572444: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.572802: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.572800: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.572952: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.573288: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.573305: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.573304: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.573582: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.573598: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.574156: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.574181: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.574187: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.574281: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.574306: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.574312: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.574696: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.576379: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.576440: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.576448: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.575999 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.576598: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.576639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.576646: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.577223: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.579014: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.582106: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.582661: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.583049: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.583068: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.583434: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.584431 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.585200: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.585552: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.585573: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.587142: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.587183: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.587191: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.587277: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.587309: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.587315: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.587575: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.587750: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.589421: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.591160: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.591257: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.591942: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.591978: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.591986: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.592072: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.592101: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.592107: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.592545: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.592249 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.594456: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.594765: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.594782: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.595383: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.595409: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.595416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.595498: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.595525: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.595531: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.596037: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.597770 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.600810: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.602048: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.603505: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.603707: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.603808: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.603824: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.603970: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.603987: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.605024 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.605906: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.605958: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.605970: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.606104: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.606151: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.606162: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.606809: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.608094: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.609606: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.609606: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.610459 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.612694: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.612755: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.612768: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.612807: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.612845: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.612876: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.612885: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.613075: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.613094: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.613467: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.613539: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.617456: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.617520: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.617527: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.617662: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.617698: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.617704: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.617481 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.618196: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.618630: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.620920: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.621228: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.621346: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.621368: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.622370 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.624971: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.625457: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.625489: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.625507: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.625520: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.625530: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.625663: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.625703: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.625710: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.626270: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.626463: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.627660: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.628986 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.630878: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.630943: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.630953: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.631091: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.631139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.631148: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.631473: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.631701: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.633904: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.633632 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.635716: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.636177: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.636192: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.636218: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.638263: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.638341: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.638355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.638661: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.638708: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.638729: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.639494: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.640527: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.640574: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.640586: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.640702: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.640753: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.640761: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.641294: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.642268 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.643036: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.644491: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.646177 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.647884: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.647902: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.648194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.648209: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.648660: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.648814: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.648856: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.648878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.648883: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.648978: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.649014: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.649024: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.649094: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.649111: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.649268: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.649286: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.649643: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.650144 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.651582: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.651637: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.651647: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.651795: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.651840: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.651847: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.652372: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.655218: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.655435: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.655442: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.657179: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.658065: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.658088: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.658398 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.661024: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.661046: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.661421: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.661441: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.661834: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.663569: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.666380: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.666146 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.666828: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.667283: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.667327: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.667339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.667456: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.667492: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.667500: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.667539: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.667566: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.667573: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.667642: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.667667: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.667673: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.667950: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.668041: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.670276: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.670315: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.670322: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.670406: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.670433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.670439: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.670869: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.670816 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.674007: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.676312: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.676479: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.676590: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.676605: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.676858: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.676876: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.677267: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.677555: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.677572: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.678098: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.678132: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.678142: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.678274: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.678312: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.678320: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.678327 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.679086: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.683594: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.683691: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.685512: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.686739: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.686405 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.688941: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.688938: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.688956: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.688978: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.688986: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.689063: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.689091: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.689097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.689306: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.689324: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.689546: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.692097 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.693019: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.693076: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.693087: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.693196: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.693238: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.693257: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.693266: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.693763: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.695221: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.696924: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.697195: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.697210: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.697794: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.697828: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.697839: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.697958: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.697992: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.698002: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.698553: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.698179 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.699893: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.700954: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.701403: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.701420: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.703737: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.704133: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.704159: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.704602: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.704700: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.704779: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.704794: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.704936: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.704980: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.704991: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.705607: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.707329: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.706566 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.709511: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.710955: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.712090: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.712352: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.712631: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.712649: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.712775 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.713459: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.713488: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.713495: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.713574: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.713601: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.713608: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.714061: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.715597: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.715651: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.715669: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.715812: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.715847: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.715854: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.716341: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.717265 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.718330: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.721321: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.722449 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.722980: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.723340: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.723354: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.723761: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.724154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.724173: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.724803: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.724844: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.724855: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.724966: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.724999: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.725007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.725546: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.726696 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.729586: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.730757: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.731721: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.733775: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.734322: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.734342: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.734173 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.734860: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.734952: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.734986: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.734994: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.735099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.735130: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.735137: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.735658: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.739252: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.739318: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.739326: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.739431: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.739464: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.739470: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.739735: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.740005: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.740798: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.740948: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.741265: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.741282: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.741841 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.744464: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.745324: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.745377: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.745388: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.745497: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.745542: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.745552: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.746042: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.747217: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.747333: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.747836: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.747862: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.747869: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.747932: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.747957: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.747964: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.748376: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.749320 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.751043: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.751086: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.751097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.751189: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.751225: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.751243: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.751770: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.754119 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.754677: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.755013: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.755031: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.755350: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.755777: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.756189: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.756209: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.756921: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.757289: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.757306: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.757380 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.758771: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.759325: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.759353: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.759488: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.759539: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.759548: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.759716: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.759761: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.759768: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.760394: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.761684: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.763920: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.764872: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.767623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.767845: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.770547: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.770581: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.770587: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.770647: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.770658: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.770671: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.770679: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.771052: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.772333: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.773792 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.774091 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.776523: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.776556: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.776563: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.776636: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.776662: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.776668: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.776967: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.776976: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.777088: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.777118: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.777129: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.777159: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.777247: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.777278: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.777287: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.777292: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.777298: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.777307: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.777313: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.777782: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.778338 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.782693: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.784845: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.786137 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.786694: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.786747: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.787093: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.787112: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.787106: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.787128: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.790719: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.790719: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.790719: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.792354: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.792676: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.795636 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.797814: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.797523 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.798209: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.798240: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.798247: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.798326: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.798355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.798361: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.798792: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.799002: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.799028: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.799035: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.799045: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.799077: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.799087: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.799093: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.799115: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.799121: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.799147: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.799188: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.799197: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.799467: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.799594: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.802252: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.802317: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.802328: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.802458: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.802500: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.802509: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.802359 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.803144: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.805744: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.806027: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.806206: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.806226: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.806263: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.806565: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.806587: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.806666: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.806686: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.809883: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.811169 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.812469: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.812469: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.812470: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.812650: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.813118: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.813144: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.814256: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.814270: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.814307: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.814317: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.814417: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.814460: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.814469: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.815188: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.818424: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.818476: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.818484: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.818574: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.818602: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.818609: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.819047: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.819753: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.819958: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.819716 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.823141: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.823433: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.823456: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.823769: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.823804: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.823811: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.823896: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.823922: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.823932: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.824408: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.824871: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.825221: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.825242: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.824949 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.827277: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.829981: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.830645: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.830799: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.831057: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.831077: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.831665: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.831700: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.831709: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.831800: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.831828: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.831834: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.832274: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.832334 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.834341: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.836141: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.837881: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.837921: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.837928: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.837981: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.837998: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.838027: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.838033: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.838282: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.838298: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.838506: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.838642: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.839202 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.842309: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.842379: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.842385: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.842540: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.842583: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.842590: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.843181: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.843249: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.843521: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.843884: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.843905: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.848841: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.849496 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.851752: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.852042: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.852089: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.852104: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.852643: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.852683: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.852694: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.852800: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.852835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.852845: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.853382: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.853397: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.853014 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.855862: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.855908: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.855915: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.856000: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.856028: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.856034: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.856398: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.856994: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.860928: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.860928: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.861232: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.861248: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.861295: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.861315: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.862028: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.862122 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.865901: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.865960: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.865967: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.866086: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.866121: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.866128: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.866617: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.866652: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.866167 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.867397: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.869362: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.871446 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.872099: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.872502: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.872520: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.873488: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.873529: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.873539: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.873656: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.873690: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.873700: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.874285: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.875201: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.877449: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.878961: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.879008: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.879044: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.879056: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.878596 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.879158: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.879195: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.879204: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.879723: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.881298: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.881579: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.881599: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.882277: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.882305: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.882312: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.882402: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.882435: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.882442: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.882841: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.883577: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.885926 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.886819: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.887144: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.887624: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.887645: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.888265: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.888308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.888321: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.888438: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.888477: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.888488: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.888900: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.888986: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.889180: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.889195: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.892251: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.894155: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.894608: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.896931: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.897214: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.897228: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.897569 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.898709: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.898749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.898760: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.898876: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.898912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.898921: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.899473: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.899058 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.900226: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.902422: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.904244: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.904276: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.904287: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.904364: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.904394: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.904402: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.904845: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.905987 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.908281: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.908638: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.908657: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.910367: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.911407 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.912804: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.913185: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.913204: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.914065: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.914851: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.914901: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.914913: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.915032: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.915073: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.915083: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.915391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.915623: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.918253: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.919036: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.919899: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.919935: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.919943: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.920023: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.920051: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.920057: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.919866 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.920526: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.922695: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.922741: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.922753: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.922851: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.922871: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.922905: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.922915: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.923389: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.923408: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.923416: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.924304 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.926039: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.926468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.926494: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.927234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.930756: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.931177: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.931224: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.931234: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.931371: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.931414: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.931422: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.931937: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.932516 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.933077: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.933299: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.933551: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.933577: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.935981: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.937284 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.939300: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.940439: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.940951: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.940961: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.940986: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.940997: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.941096: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.941129: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.941139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.941304: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.941321: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.941611: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.942012 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.943358: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.943405: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.943415: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.943541: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.943577: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.943583: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.944082: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.946979: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.949019: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.949265: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.949494: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.949518: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.950126 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.951169: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.951546: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.951565: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.953823: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.953900: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.953911: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.954045: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.954091: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.954099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.954752: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.954336 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.955266: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.955612: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.957040: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.957935: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.961165: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.961208: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.961214: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.961306: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.961341: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.961349: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.961796: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.962219 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.962885: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.962914: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.962923: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.963012: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.963042: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.963050: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.963525: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.963544: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.963954: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.963973: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.966234 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.967740: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.971041: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.971316: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.971573: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.971774: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.971800: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.972093: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.972111: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.972972: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.973014: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.973025: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.973074: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.973141: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.973183: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.973194: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.973104 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.973879: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.977618: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.977618: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.977723: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.977759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.977769: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.977896: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.977934: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.977943: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.978572: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.979096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.980969: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.981319: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.981337: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.982775: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.982811: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.982828: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.982852: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.982908: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.982938: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.982944: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.983460: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.983875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.984265: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.984283: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.986596: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.986641: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.986649: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.986691: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:14.986738: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.986769: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.986775: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.986326 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.987336: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.988456: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.988822 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:14.989781: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.990714: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:14.990741: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:14.990748: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:14.990826: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:14.990851: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:14.990861: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:14.991210: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:14.991836: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.992187: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.992203: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:14.996124: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:14.996984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:14.997297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:14.997316: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:14.998232 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.001098: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.001448: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.001469: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.002358: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.002991: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.002993: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.002515 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.007272: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.009300: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.009409: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.009428: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.008950 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.009613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.009609: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.009650: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.009665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.009661: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.009674: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.009788: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.009832: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.009842: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.010507: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.010508: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.011326: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.014175 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.014990: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.015041: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.015049: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.015151: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.015185: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.015191: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.015359: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.015689: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.017012: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.017441: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.017466: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.017892: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.018237: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.018268: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.018890: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.018916: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.018923: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.019004: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.019039: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.019049: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.019457: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.020963: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.021375: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.021403: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.022854 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.023794: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.024639: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.024639: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.026653: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.026972: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.026992: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.027546: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.027575: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.027582: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.027682: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.027712: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.027718: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.028140: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.028239: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.028031 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.029548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.032419: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.033096: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.033141: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.033154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.033287: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.033334: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.033344: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.033821: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.034304 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.037007: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.037595: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.037611: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.038858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.039690: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.041452 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.042890: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.043139: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.043279: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.043299: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.045809: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.045864: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.045874: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.045994: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.046027: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.046034: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.046365: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.046395: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.046402: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.046524: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.046050 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.046553: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.046561: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.046562: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.047004: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.050006: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.050011: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.053468: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.053508: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.053515: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.053598: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.053625: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.053631: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.054094: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.054702: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.054218 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.056279: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.056479: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.056614: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.056634: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.056940: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.056961: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.057681: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.057717: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.057726: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.057835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.057867: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.057876: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.058518: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.059921: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.061563: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.061563: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.063575: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.063607: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.063613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.063691: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.063717: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.063723: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.064115: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.064321: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.064377: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.064622: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.064640: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.064645: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.064657: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.065545 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.069555: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.069555: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.070288: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.070310 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.073135: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.073437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.073453: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.074584: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.074616: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.074625: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.074717: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.074749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.074759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.075239: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.077078: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.077041 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.079140: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.080971: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.081010: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.081017: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.081106: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.081159: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.081165: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.081591: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.082261 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.083202: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.083558: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.083577: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.084610: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.088429: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.088592: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.088625: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.088633: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.088736: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.088783: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.088790: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.089038: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.089330: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.089405: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.089427: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.089123 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.092373: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.096197: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.096556: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.096590: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.096600: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.096705: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.096756: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.096768: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.097020: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.097391: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.097402: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.097422: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.098446 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.100197: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.101423 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.103711: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.103938: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.104081: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.104103: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.104684: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.104721: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.104728: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.104865: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.104907: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.104913: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.105419: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.106223 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.108004: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.110785: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.112296: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.112345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.112353: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.112493: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.112528: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.112535: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.113058: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.113437: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.113923: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.113949: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.114176: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.114176: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.113776 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.120442: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.120947: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.120997: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.121034: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.121042: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.121185: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.121217: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.121224: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.121357: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.121366: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.121386: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.121395: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.121404: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.121502: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.121540: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.121548: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.121834: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.122177: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.122784: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.122454 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.127144: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.127508: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.127555: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.127564: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.127573: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.127577: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.127789: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.127841: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.127852: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.128229: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.128514: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.129935: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.129396 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.133065: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.133569: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.133610: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.134306: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.134359: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.134373: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.134514: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.134560: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.134570: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.135129: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.137171 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.139282: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.140638: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.140954: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.140989: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.141366: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.141384: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.141437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.141454: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.143127: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.145222: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.145279: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.145297: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.145455: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.145503: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.145510: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.146002: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.146824: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.148918: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.149395: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.150120 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.150556: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.150607: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.150614: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.150692: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.150717: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.150723: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.151088: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.151624: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.151899: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.151914: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.153560: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.156940: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.157267: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.157286: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.157887: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.157923: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.157945: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.158055: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.158091: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.158101: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.158200: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.158013 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.158657: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.159313 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.164180: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.165932: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.166356 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.168754: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.169355: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.169374: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.169720: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.169759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.169770: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.169884: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.169921: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.169930: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.170446: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.170366 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.171354: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.171355: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.176952: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.177301: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.177319: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.177348: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.177385: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.177378: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.177395: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.177543: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.177576: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.177584: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.177616: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.177642: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.177649: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.177743: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.177772: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.177778: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.178177: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.178210: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.178068 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.181922: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.184976: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.185283: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.185398: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.185420: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.185862: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.185892: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.185924: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.185932: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.186009: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.186040: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.186046: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.186598: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.186547 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.188983: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.189384: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.189409: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.190091: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.190128: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.190135: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.190243: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.190274: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.190281: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.190785: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.190904 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.192436: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.192899: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.192925: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.193650: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.196900: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.198302 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.199790: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.200413: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.200948: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.200971: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.201087: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.201441: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.201477: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.201485: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.201614: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.201648: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.201654: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.202144: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.203645 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.206523: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.208596: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.209015: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.209038: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.209029: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.210699: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.210432 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.211486: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.211535: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.211547: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.211671: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.211713: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.211722: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.212385: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.213390: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.215602: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.215667: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.215679: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.215814: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.215865: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.215876: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.216528: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.217912: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.217976: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.217985: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.218010: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.218078: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.218107: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.218113: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.218213: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.218798: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.218651 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.219770: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.220249: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.220286: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.221832: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.221869: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.221875: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.221970: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.221999: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.222005: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.222454: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.223141: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.223529: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.223552: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.225281 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.227786: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.228223: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.228366: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.228393: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.228571: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.228626: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.228648: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.230372: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.232206: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.234244: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.234493 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.236955: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.236955: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.239994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.241953 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.244695 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.247707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.250236 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.255604: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.255611: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.255875 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.258970: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.259008: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.259015: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.259096: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.259120: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.259126: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.259537: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.261497: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.261954 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.264689: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.264973: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.265008: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.265016: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.265069: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.265089: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.265159: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.265200: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.265210: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.265641: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.266055 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.268072: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.271834: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.271885: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.271893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.271985: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.272017: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.272024: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.272232: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-20 11:45:15.272487: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.272139 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.272877: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.273312: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.273332: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.275258: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
WARNING: Logging before flag parsing goes to stderr.
W0720 11:45:15.278175 140474206881600 deprecation_wrapper.py:119] From tf_process_mp.py:8: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-20 11:45:15.278803: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-07-20 11:45:15.279384: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c49fba0a0 executing computations on platform Host. Devices:
2019-07-20 11:45:15.279410: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-20 11:45:15.279698: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.279734: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.279742: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.279867: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.279900: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.279906: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.280411: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.280689: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
2019-07-20 11:45:15.281769: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-07-20 11:45:15.286240: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.286286: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.286299: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
2019-07-20 11:45:15.286387: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.286421: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.286433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.286975: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
2019-07-20 11:45:15.288108: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.288137: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.288144: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.288216: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.288241: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.288247: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.288624: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
2019-07-20 11:45:15.290185: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.290222: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.290230: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.290317: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.290348: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.290355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.290801: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
2019-07-20 11:45:15.292313: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.292355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.292366: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.292459: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.292496: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.292506: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.293019: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
2019-07-20 11:45:15.302438: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.302492: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.302504: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.302604: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.302640: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.302651: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.302911: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-07-20 11:45:15.302943: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mxxmhh
2019-07-20 11:45:15.302954: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mxxmhh
2019-07-20 11:45:15.303043: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.26.0
2019-07-20 11:45:15.303076: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 430.26.0
2019-07-20 11:45:15.303086: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 430.26.0
2019-07-20 11:45:15.303216: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-20 11:45:15.303558: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
[[1. 1.]]
before A, thread  0 0
after A, thread  0 1
before B, thread  0 1
after B, thread  0 2
before A, thread  0 2
after A, thread  0 3
before B, thread  0 3
after B, thread  0 4
before A, thread  0 4
after A, thread  0 5
before B, thread  0 5
after B, thread  0 6
before A, thread  0 6
after A, thread  0 7
before B, thread  0 7
after B, thread  0 8
before A, thread  0 8
after A, thread  0 9
before B, thread  0 9
after B, thread  0 10
before A, thread  0 10
after A, thread  0 11
before B, thread  0 11
after B, thread  0 12
0  done
[[1. 1.]]
before A, thread  82 0
after A, thread  82 1
before B, thread  82 1
after B, thread  82 2
before A, thread  82 2
after A, thread  82 3
before B, thread  82 3
after B, thread  82 4
before A, thread  82 4
after A, thread  82 5
before B, thread  82 5
after B, thread  82 6
before A, thread  82 6
after A, thread  82 7
before B, thread  82 7
after B, thread  82 8
before A, thread  82 8
after A, thread  82 9
before B, thread  82 9
after B, thread  82 10
before A, thread  82 10
after A, thread  82 11
before B, thread  82 11
after B, thread  82 12
82  done
[[1. 1.]]
before A, thread  83 0
after A, thread  83 1
before B, thread  83 1
after B, thread  83 2
before A, thread  83 2
after A, thread  83 3
before B, thread  83 3
after B, thread  83 4
before A, thread  83 4
after A, thread  83 5
before B, thread  83 5
after B, thread  83 6
before A, thread  83 6
after A, thread  83 7
before B, thread  83 7
after B, thread  83 8
before A, thread  83 8
after A, thread  83 9
before B, thread  83 9
after B, thread  83 10
before A, thread  83 10
after A, thread  83 11
before B, thread  83 11
after B, thread  83 12
83  done
[[1. 1.]]
before A, thread  11 0
after A, thread  11 1
before B, thread  11 1
after B, thread  11 2
before A, thread  11 2
after A, thread  11 3
before B, thread  11 3
after B, thread  11 4
before A, thread  11 4
after A, thread  11 5
before B, thread  11 5
after B, thread  11 6
before A, thread  11 6
after A, thread  11 7
before B, thread  11 7
after B, thread  11 8
before A, thread  11 8
after A, thread  11 9
before B, thread  11 9
after B, thread  11 10
before A, thread  11 10
after A, thread  11 11
before B, thread  11 11
after B, thread  11 12
11  done
[[1. 1.]]
before A, thread  44 0
after A, thread  44 1
before B, thread  44 1
after B, thread  44 2
before A, thread  44 2
after A, thread  44 3
before B, thread  44 3
after B, thread  44 4
before A, thread  44 4
after A, thread  44 5
before B, thread  44 5
after B, thread  44 6
before A, thread  44 6
after A, thread  44 7
before B, thread  44 7
after B, thread  44 8
before A, thread  44 8
after A, thread  44 9
before B, thread  44 9
after B, thread  44 10
before A, thread  44 10
after A, thread  44 11
before B, thread  44 11
after B, thread  44 12
44  done
[[1. 1.]]
before A, thread  45 0
after A, thread  45 1
before B, thread  45 1
after B, thread  45 2
before A, thread  45 2
after A, thread  45 3
before B, thread  45 3
after B, thread  45 4
before A, thread  45 4
after A, thread  45 5
before B, thread  45 5
after B, thread  45 6
before A, thread  45 6
after A, thread  45 7
before B, thread  45 7
after B, thread  45 8
before A, thread  45 8
after A, thread  45 9
before B, thread  45 9
after B, thread  45 10
before A, thread  45 10
after A, thread  45 11
before B, thread  45 11
after B, thread  45 12
45  done
[[1. 1.]]
before A, thread  36 0
after A, thread  36 1
before B, thread  36 1
after B, thread  36 2
before A, thread  36 2
after A, thread  36 3
before B, thread  36 3
after B, thread  36 4
before A, thread  36 4
after A, thread  36 5
before B, thread  36 5
after B, thread  36 6
before A, thread  36 6
after A, thread  36 7
before B, thread  36 7
after B, thread  36 8
before A, thread  36 8
after A, thread  36 9
before B, thread  36 9
after B, thread  36 10
before A, thread  36 10
after A, thread  36 11
before B, thread  36 11
after B, thread  36 12
36  done
[[1. 1.]]
before A, thread  9 0
after A, thread  9 1
before B, thread  9 1
after B, thread  9 2
before A, thread  9 2
after A, thread  9 3
before B, thread  9 3
after B, thread  9 4
before A, thread  9 4
after A, thread  9 5
before B, thread  9 5
after B, thread  9 6
before A, thread  9 6
after A, thread  9 7
before B, thread  9 7
after B, thread  9 8
before A, thread  9 8
after A, thread  9 9
before B, thread  9 9
after B, thread  9 10
before A, thread  9 10
after A, thread  9 11
before B, thread  9 11
after B, thread  9 12
9  done
[[1. 1.]]
before A, thread  20 0
after A, thread  20 1
before B, thread  20 1
after B, thread  20 2
before A, thread  20 2
after A, thread  20 3
before B, thread  20 3
after B, thread  20 4
before A, thread  20 4
after A, thread  20 5
before B, thread  20 5
after B, thread  20 6
before A, thread  20 6
after A, thread  20 7
before B, thread  20 7
after B, thread  20 8
before A, thread  20 8
after A, thread  20 9
before B, thread  20 9
after B, thread  20 10
before A, thread  20 10
after A, thread  20 11
before B, thread  20 11
after B, thread  20 12
20  done
[[1. 1.]]
before A, thread  26 0
after A, thread  26 1
before B, thread  26 1
after B, thread  26 2
before A, thread  26 2
after A, thread  26 3
before B, thread  26 3
after B, thread  26 4
before A, thread  26 4
after A, thread  26 5
before B, thread  26 5
after B, thread  26 6
before A, thread  26 6
after A, thread  26 7
before B, thread  26 7
after B, thread  26 8
before A, thread  26 8
after A, thread  26 9
before B, thread  26 9
after B, thread  26 10
before A, thread  26 10
after A, thread  26 11
before B, thread  26 11
after B, thread  26 12
26  done
[[1. 1.]]
before A, thread  59 0
after A, thread  59 1
before B, thread  59 1
after B, thread  59 2
before A, thread  59 2
after A, thread  59 3
before B, thread  59 3
after B, thread  59 4
before A, thread  59 4
after A, thread  59 5
before B, thread  59 5
after B, thread  59 6
before A, thread  59 6
after A, thread  59 7
before B, thread  59 7
after B, thread  59 8
before A, thread  59 8
after A, thread  59 9
before B, thread  59 9
after B, thread  59 10
before A, thread  59 10
after A, thread  59 11
before B, thread  59 11
after B, thread  59 12
59  done
[[1. 1.]]
before A, thread  182 0
after A, thread  182 1
before B, thread  182 1
after B, thread  182 2
before A, thread  182 2
after A, thread  182 3
before B, thread  182 3
after B, thread  182 4
before A, thread  182 4
after A, thread  182 5
before B, thread  182 5
after B, thread  182 6
before A, thread  182 6
after A, thread  182 7
before B, thread  182 7
after B, thread  182 8
before A, thread  182 8
after A, thread  182 9
before B, thread  182 9
after B, thread  182 10
before A, thread  182 10
after A, thread  182 11
before B, thread  182 11
after B, thread  182 12
182  done
[[1. 1.]]
before A, thread  29 0
after A, thread  29 1
before B, thread  29 1
after B, thread  29 2
before A, thread  29 2
after A, thread  29 3
before B, thread  29 3
after B, thread  29 4
before A, thread  29 4
after A, thread  29 5
before B, thread  29 5
after B, thread  29 6
before A, thread  29 6
after A, thread  29 7
before B, thread  29 7
after B, thread  29 8
before A, thread  29 8
after A, thread  29 9
before B, thread  29 9
after B, thread  29 10
before A, thread  29 10
after A, thread  29 11
before B, thread  29 11
after B, thread  29 12
29  done
[[1. 1.]]
before A, thread  108 0
after A, thread  108 1
before B, thread  108 1
after B, thread  108 2
before A, thread  108 2
after A, thread  108 3
before B, thread  108 3
after B, thread  108 4
before A, thread  108 4
after A, thread  108 5
before B, thread  108 5
after B, thread  108 6
before A, thread  108 6
after A, thread  108 7
before B, thread  108 7
after B, thread  108 8
before A, thread  108 8
after A, thread  108 9
before B, thread  108 9
after B, thread  108 10
before A, thread  108 10
after A, thread  108 11
before B, thread  108 11
after B, thread  108 12
108  done
[[1. 1.]]
before A, thread  73 0
after A, thread  73 1
before B, thread  73 1
after B, thread  73 2
before A, thread  73 2
after A, thread  73 3
before B, thread  73 3
after B, thread  73 4
before A, thread  73 4
after A, thread  73 5
before B, thread  73 5
after B, thread  73 6
before A, thread  73 6
after A, thread  73 7
before B, thread  73 7
after B, thread  73 8
before A, thread  73 8
after A, thread  73 9
before B, thread  73 9
after B, thread  73 10
before A, thread  73 10
after A, thread  73 11
before B, thread  73 11
after B, thread  73 12
73  done
[[1. 1.]]
before A, thread  23 0
after A, thread  23 1
before B, thread  23 1
after B, thread  23 2
before A, thread  23 2
after A, thread  23 3
before B, thread  23 3
after B, thread  23 4
before A, thread  23 4
after A, thread  23 5
before B, thread  23 5
after B, thread  23 6
before A, thread  23 6
after A, thread  23 7
before B, thread  23 7
after B, thread  23 8
before A, thread  23 8
after A, thread  23 9
before B, thread  23 9
after B, thread  23 10
before A, thread  23 10
after A, thread  23 11
before B, thread  23 11
after B, thread  23 12
23  done
[[1. 1.]]
before A, thread  30 0
after A, thread  30 1
before B, thread  30 1
after B, thread  30 2
before A, thread  30 2
after A, thread  30 3
before B, thread  30 3
after B, thread  30 4
before A, thread  30 4
after A, thread  30 5
before B, thread  30 5
after B, thread  30 6
before A, thread  30 6
after A, thread  30 7
before B, thread  30 7
after B, thread  30 8
before A, thread  30 8
after A, thread  30 9
before B, thread  30 9
after B, thread  30 10
before A, thread  30 10
after A, thread  30 11
before B, thread  30 11
after B, thread  30 12
30  done
[[1. 1.]]
before A, thread  14 0
after A, thread  14 1
before B, thread  14 1
after B, thread  14 2
before A, thread  14 2
after A, thread  14 3
before B, thread  14 3
after B, thread  14 4
before A, thread  14 4
after A, thread  14 5
before B, thread  14 5
after B, thread  14 6
before A, thread  14 6
after A, thread  14 7
before B, thread  14 7
after B, thread  14 8
before A, thread  14 8
after A, thread  14 9
before B, thread  14 9
after B, thread  14 10
before A, thread  14 10
after A, thread  14 11
before B, thread  14 11
after B, thread  14 12
14  done
[[1. 1.]]
before A, thread  8 0
after A, thread  8 1
before B, thread  8 1
after B, thread  8 2
before A, thread  8 2
after A, thread  8 3
before B, thread  8 3
after B, thread  8 4
before A, thread  8 4
after A, thread  8 5
before B, thread  8 5
after B, thread  8 6
before A, thread  8 6
after A, thread  8 7
before B, thread  8 7
after B, thread  8 8
before A, thread  8 8
after A, thread  8 9
before B, thread  8 9
after B, thread  8 10
before A, thread  8 10
after A, thread  8 11
before B, thread  8 11
after B, thread  8 12
8  done
[[1. 1.]]
before A, thread  63 0
after A, thread  63 1
before B, thread  63 1
after B, thread  63 2
before A, thread  63 2
after A, thread  63 3
before B, thread  63 3
after B, thread  63 4
before A, thread  63 4
after A, thread  63 5
before B, thread  63 5
after B, thread  63 6
before A, thread  63 6
after A, thread  63 7
before B, thread  63 7
after B, thread  63 8
before A, thread  63 8
after A, thread  63 9
before B, thread  63 9
after B, thread  63 10
before A, thread  63 10
after A, thread  63 11
before B, thread  63 11
after B, thread  63 12
63  done
[[1. 1.]]
before A, thread  70 0
after A, thread  70 1
before B, thread  70 1
after B, thread  70 2
before A, thread  70 2
after A, thread  70 3
before B, thread  70 3
after B, thread  70 4
before A, thread  70 4
after A, thread  70 5
before B, thread  70 5
after B, thread  70 6
before A, thread  70 6
after A, thread  70 7
before B, thread  70 7
after B, thread  70 8
before A, thread  70 8
after A, thread  70 9
before B, thread  70 9
after B, thread  70 10
before A, thread  70 10
after A, thread  70 11
before B, thread  70 11
after B, thread  70 12
70  done
[[1. 1.]]
before A, thread  37 0
after A, thread  37 1
before B, thread  37 1
after B, thread  37 2
before A, thread  37 2
after A, thread  37 3
before B, thread  37 3
after B, thread  37 4
before A, thread  37 4
after A, thread  37 5
before B, thread  37 5
after B, thread  37 6
before A, thread  37 6
after A, thread  37 7
before B, thread  37 7
after B, thread  37 8
before A, thread  37 8
after A, thread  37 9
before B, thread  37 9
after B, thread  37 10
before A, thread  37 10
after A, thread  37 11
before B, thread  37 11
after B, thread  37 12
37  done
[[1. 1.]]
before A, thread  27 0
after A, thread  27 1
before B, thread  27 1
after B, thread  27 2
before A, thread  27 2
after A, thread  27 3
before B, thread  27 3
after B, thread  27 4
before A, thread  27 4
after A, thread  27 5
before B, thread  27 5
after B, thread  27 6
before A, thread  27 6
after A, thread  27 7
before B, thread  27 7
after B, thread  27 8
before A, thread  27 8
after A, thread  27 9
before B, thread  27 9
after B, thread  27 10
before A, thread  27 10
after A, thread  27 11
before B, thread  27 11
after B, thread  27 12
27  done
[[1. 1.]]
before A, thread  43 0
after A, thread  43 1
before B, thread  43 1
after B, thread  43 2
before A, thread  43 2
after A, thread  43 3
before B, thread  43 3
after B, thread  43 4
before A, thread  43 4
after A, thread  43 5
before B, thread  43 5
after B, thread  43 6
before A, thread  43 6
after A, thread  43 7
before B, thread  43 7
after B, thread  43 8
before A, thread  43 8
after A, thread  43 9
before B, thread  43 9
after B, thread  43 10
before A, thread  43 10
after A, thread  43 11
before B, thread  43 11
after B, thread  43 12
43  done
[[1. 1.]]
before A, thread  17 0
after A, thread  17 1
before B, thread  17 1
after B, thread  17 2
before A, thread  17 2
after A, thread  17 3
before B, thread  17 3
after B, thread  17 4
before A, thread  17 4
after A, thread  17 5
before B, thread  17 5
after B, thread  17 6
before A, thread  17 6
after A, thread  17 7
before B, thread  17 7
after B, thread  17 8
before A, thread  17 8
after A, thread  17 9
before B, thread  17 9
after B, thread  17 10
before A, thread  17 10
after A, thread  17 11
before B, thread  17 11
after B, thread  17 12
17  done
[[1. 1.]]
before A, thread  2 0
after A, thread  2 1
before B, thread  2 1
after B, thread  2 2
before A, thread  2 2
after A, thread  2 3
before B, thread  2 3
after B, thread  2 4
before A, thread  2 4
after A, thread  2 5
before B, thread  2 5
after B, thread  2 6
before A, thread  2 6
after A, thread  2 7
before B, thread  2 7
after B, thread  2 8
before A, thread  2 8
after A, thread  2 9
before B, thread  2 9
after B, thread  2 10
before A, thread  2 10
after A, thread  2 11
before B, thread  2 11
after B, thread  2 12
2  done
[[1. 1.]]
before A, thread  24 0
after A, thread  24 1
before B, thread  24 1
after B, thread  24 2
before A, thread  24 2
after A, thread  24 3
before B, thread  24 3
after B, thread  24 4
before A, thread  24 4
after A, thread  24 5
before B, thread  24 5
after B, thread  24 6
before A, thread  24 6
after A, thread  24 7
before B, thread  24 7
after B, thread  24 8
before A, thread  24 8
after A, thread  24 9
before B, thread  24 9
after B, thread  24 10
before A, thread  24 10
after A, thread  24 11
before B, thread  24 11
after B, thread  24 12
24  done
[[1. 1.]]
before A, thread  139 0
after A, thread  139 1
before B, thread  139 1
after B, thread  139 2
before A, thread  139 2
after A, thread  139 3
before B, thread  139 3
after B, thread  139 4
before A, thread  139 4
after A, thread  139 5
before B, thread  139 5
after B, thread  139 6
before A, thread  139 6
after A, thread  139 7
before B, thread  139 7
after B, thread  139 8
before A, thread  139 8
after A, thread  139 9
before B, thread  139 9
after B, thread  139 10
before A, thread  139 10
after A, thread  139 11
before B, thread  139 11
after B, thread  139 12
139  done
[[1. 1.]]
before A, thread  184 0
after A, thread  184 1
before B, thread  184 1
after B, thread  184 2
before A, thread  184 2
after A, thread  184 3
before B, thread  184 3
after B, thread  184 4
before A, thread  184 4
after A, thread  184 5
before B, thread  184 5
after B, thread  184 6
before A, thread  184 6
after A, thread  184 7
before B, thread  184 7
after B, thread  184 8
before A, thread  184 8
after A, thread  184 9
before B, thread  184 9
after B, thread  184 10
before A, thread  184 10
after A, thread  184 11
before B, thread  184 11
after B, thread  184 12
184  done
[[1. 1.]]
before A, thread  90 0
after A, thread  90 1
before B, thread  90 1
after B, thread  90 2
before A, thread  90 2
after A, thread  90 3
before B, thread  90 3
after B, thread  90 4
before A, thread  90 4
after A, thread  90 5
before B, thread  90 5
after B, thread  90 6
before A, thread  90 6
after A, thread  90 7
before B, thread  90 7
after B, thread  90 8
before A, thread  90 8
after A, thread  90 9
before B, thread  90 9
after B, thread  90 10
before A, thread  90 10
after A, thread  90 11
before B, thread  90 11
after B, thread  90 12
90  done
[[1. 1.]]
before A, thread  68 0
after A, thread  68 1
before B, thread  68 1
after B, thread  68 2
before A, thread  68 2
after A, thread  68 3
before B, thread  68 3
after B, thread  68 4
before A, thread  68 4
after A, thread  68 5
before B, thread  68 5
after B, thread  68 6
before A, thread  68 6
after A, thread  68 7
before B, thread  68 7
after B, thread  68 8
before A, thread  68 8
after A, thread  68 9
before B, thread  68 9
after B, thread  68 10
before A, thread  68 10
after A, thread  68 11
before B, thread  68 11
after B, thread  68 12
68  done
[[1. 1.]]
before A, thread  193 0
after A, thread  193 1
before B, thread  193 1
after B, thread  193 2
before A, thread  193 2
after A, thread  193 3
before B, thread  193 3
after B, thread  193 4
before A, thread  193 4
after A, thread  193 5
before B, thread  193 5
after B, thread  193 6
before A, thread  193 6
after A, thread  193 7
before B, thread  193 7
after B, thread  193 8
before A, thread  193 8
after A, thread  193 9
before B, thread  193 9
after B, thread  193 10
before A, thread  193 10
after A, thread  193 11
before B, thread  193 11
after B, thread  193 12
193  done
[[1. 1.]]
before A, thread  135 0
after A, thread  135 1
before B, thread  135 1
after B, thread  135 2
before A, thread  135 2
after A, thread  135 3
before B, thread  135 3
after B, thread  135 4
before A, thread  135 4
after A, thread  135 5
before B, thread  135 5
after B, thread  135 6
before A, thread  135 6
after A, thread  135 7
before B, thread  135 7
after B, thread  135 8
before A, thread  135 8
after A, thread  135 9
before B, thread  135 9
after B, thread  135 10
before A, thread  135 10
after A, thread  135 11
before B, thread  135 11
after B, thread  135 12
135  done
[[1. 1.]]
before A, thread  138 0
after A, thread  138 1
before B, thread  138 1
after B, thread  138 2
before A, thread  138 2
after A, thread  138 3
before B, thread  138 3
after B, thread  138 4
before A, thread  138 4
after A, thread  138 5
before B, thread  138 5
after B, thread  138 6
before A, thread  138 6
after A, thread  138 7
before B, thread  138 7
after B, thread  138 8
before A, thread  138 8
after A, thread  138 9
before B, thread  138 9
after B, thread  138 10
before A, thread  138 10
after A, thread  138 11
before B, thread  138 11
after B, thread  138 12
138  done
[[1. 1.]]
before A, thread  4 0
after A, thread  4 1
before B, thread  4 1
after B, thread  4 2
before A, thread  4 2
after A, thread  4 3
before B, thread  4 3
after B, thread  4 4
before A, thread  4 4
after A, thread  4 5
before B, thread  4 5
after B, thread  4 6
before A, thread  4 6
after A, thread  4 7
before B, thread  4 7
after B, thread  4 8
before A, thread  4 8
after A, thread  4 9
before B, thread  4 9
after B, thread  4 10
before A, thread  4 10
after A, thread  4 11
before B, thread  4 11
after B, thread  4 12
4  done
[[1. 1.]]
before A, thread  61 0
after A, thread  61 1
before B, thread  61 1
after B, thread  61 2
before A, thread  61 2
after A, thread  61 3
before B, thread  61 3
after B, thread  61 4
before A, thread  61 4
after A, thread  61 5
before B, thread  61 5
after B, thread  61 6
before A, thread  61 6
after A, thread  61 7
before B, thread  61 7
after B, thread  61 8
before A, thread  61 8
after A, thread  61 9
before B, thread  61 9
after B, thread  61 10
before A, thread  61 10
after A, thread  61 11
before B, thread  61 11
after B, thread  61 12
61  done
[[1. 1.]]
before A, thread  40 0
after A, thread  40 1
before B, thread  40 1
after B, thread  40 2
before A, thread  40 2
after A, thread  40 3
before B, thread  40 3
after B, thread  40 4
before A, thread  40 4
after A, thread  40 5
before B, thread  40 5
after B, thread  40 6
before A, thread  40 6
after A, thread  40 7
before B, thread  40 7
after B, thread  40 8
before A, thread  40 8
after A, thread  40 9
before B, thread  40 9
after B, thread  40 10
before A, thread  40 10
after A, thread  40 11
before B, thread  40 11
after B, thread  40 12
40  done
[[1. 1.]]
before A, thread  76 0
after A, thread  76 1
before B, thread  76 1
after B, thread  76 2
before A, thread  76 2
after A, thread  76 3
before B, thread  76 3
after B, thread  76 4
before A, thread  76 4
after A, thread  76 5
before B, thread  76 5
after B, thread  76 6
before A, thread  76 6
after A, thread  76 7
before B, thread  76 7
after B, thread  76 8
before A, thread  76 8
after A, thread  76 9
before B, thread  76 9
after B, thread  76 10
before A, thread  76 10
after A, thread  76 11
before B, thread  76 11
after B, thread  76 12
76  done
[[1. 1.]]
before A, thread  102 0
after A, thread  102 1
before B, thread  102 1
after B, thread  102 2
before A, thread  102 2
after A, thread  102 3
before B, thread  102 3
after B, thread  102 4
before A, thread  102 4
after A, thread  102 5
before B, thread  102 5
after B, thread  102 6
before A, thread  102 6
after A, thread  102 7
before B, thread  102 7
after B, thread  102 8
before A, thread  102 8
after A, thread  102 9
before B, thread  102 9
after B, thread  102 10
before A, thread  102 10
after A, thread  102 11
before B, thread  102 11
after B, thread  102 12
102  done
[[1. 1.]]
before A, thread  55 0
after A, thread  55 1
before B, thread  55 1
after B, thread  55 2
before A, thread  55 2
after A, thread  55 3
before B, thread  55 3
after B, thread  55 4
before A, thread  55 4
after A, thread  55 5
before B, thread  55 5
after B, thread  55 6
before A, thread  55 6
after A, thread  55 7
before B, thread  55 7
after B, thread  55 8
before A, thread  55 8
after A, thread  55 9
before B, thread  55 9
after B, thread  55 10
before A, thread  55 10
after A, thread  55 11
before B, thread  55 11
after B, thread  55 12
55  done
[[1. 1.]]
before A, thread  180 0
after A, thread  180 1
before B, thread  180 1
after B, thread  180 2
before A, thread  180 2
after A, thread  180 3
before B, thread  180 3
after B, thread  180 4
before A, thread  180 4
after A, thread  180 5
before B, thread  180 5
after B, thread  180 6
before A, thread  180 6
after A, thread  180 7
before B, thread  180 7
after B, thread  180 8
before A, thread  180 8
after A, thread  180 9
before B, thread  180 9
after B, thread  180 10
before A, thread  180 10
after A, thread  180 11
before B, thread  180 11
after B, thread  180 12
180  done
[[1. 1.]]
before A, thread  71 0
after A, thread  71 1
before B, thread  71 1
after B, thread  71 2
before A, thread  71 2
after A, thread  71 3
before B, thread  71 3
after B, thread  71 4
before A, thread  71 4
after A, thread  71 5
before B, thread  71 5
after B, thread  71 6
before A, thread  71 6
after A, thread  71 7
before B, thread  71 7
after B, thread  71 8
before A, thread  71 8
after A, thread  71 9
before B, thread  71 9
after B, thread  71 10
before A, thread  71 10
after A, thread  71 11
before B, thread  71 11
after B, thread  71 12
71  done
[[1. 1.]]
before A, thread  15 0
after A, thread  15 1
before B, thread  15 1
after B, thread  15 2
before A, thread  15 2
after A, thread  15 3
before B, thread  15 3
after B, thread  15 4
before A, thread  15 4
after A, thread  15 5
before B, thread  15 5
after B, thread  15 6
before A, thread  15 6
after A, thread  15 7
before B, thread  15 7
after B, thread  15 8
before A, thread  15 8
after A, thread  15 9
before B, thread  15 9
after B, thread  15 10
before A, thread  15 10
after A, thread  15 11
before B, thread  15 11
after B, thread  15 12
15  done
[[1. 1.]]
before A, thread  201 0
after A, thread  201 1
before B, thread  201 1
after B, thread  201 2
before A, thread  201 2
after A, thread  201 3
before B, thread  201 3
after B, thread  201 4
before A, thread  201 4
after A, thread  201 5
before B, thread  201 5
after B, thread  201 6
before A, thread  201 6
after A, thread  201 7
before B, thread  201 7
after B, thread  201 8
before A, thread  201 8
after A, thread  201 9
before B, thread  201 9
after B, thread  201 10
before A, thread  201 10
after A, thread  201 11
before B, thread  201 11
after B, thread  201 12
201  done
[[1. 1.]]
before A, thread  121 0
after A, thread  121 1
before B, thread  121 1
after B, thread  121 2
before A, thread  121 2
after A, thread  121 3
before B, thread  121 3
after B, thread  121 4
before A, thread  121 4
after A, thread  121 5
before B, thread  121 5
after B, thread  121 6
before A, thread  121 6
after A, thread  121 7
before B, thread  121 7
after B, thread  121 8
before A, thread  121 8
after A, thread  121 9
before B, thread  121 9
after B, thread  121 10
before A, thread  121 10
after A, thread  121 11
before B, thread  121 11
after B, thread  121 12
121  done
[[1. 1.]]
before A, thread  7 0
after A, thread  7 1
before B, thread  7 1
after B, thread  7 2
before A, thread  7 2
after A, thread  7 3
before B, thread  7 3
after B, thread  7 4
before A, thread  7 4
after A, thread  7 5
before B, thread  7 5
after B, thread  7 6
before A, thread  7 6
after A, thread  7 7
before B, thread  7 7
after B, thread  7 8
before A, thread  7 8
after A, thread  7 9
before B, thread  7 9
after B, thread  7 10
before A, thread  7 10
after A, thread  7 11
before B, thread  7 11
after B, thread  7 12
7  done
[[1. 1.]]
before A, thread  208 0
after A, thread  208 1
before B, thread  208 1
after B, thread  208 2
before A, thread  208 2
after A, thread  208 3
before B, thread  208 3
after B, thread  208 4
before A, thread  208 4
after A, thread  208 5
before B, thread  208 5
after B, thread  208 6
before A, thread  208 6
after A, thread  208 7
before B, thread  208 7
after B, thread  208 8
before A, thread  208 8
after A, thread  208 9
before B, thread  208 9
after B, thread  208 10
before A, thread  208 10
after A, thread  208 11
before B, thread  208 11
after B, thread  208 12
208  done
[[1. 1.]]
before A, thread  1 0
after A, thread  1 1
before B, thread  1 1
after B, thread  1 2
before A, thread  1 2
after A, thread  1 3
before B, thread  1 3
after B, thread  1 4
before A, thread  1 4
after A, thread  1 5
before B, thread  1 5
after B, thread  1 6
before A, thread  1 6
after A, thread  1 7
before B, thread  1 7
after B, thread  1 8
before A, thread  1 8
after A, thread  1 9
before B, thread  1 9
after B, thread  1 10
before A, thread  1 10
after A, thread  1 11
before B, thread  1 11
after B, thread  1 12
1  done
[[1. 1.]]
before A, thread  110 0
after A, thread  110 1
before B, thread  110 1
after B, thread  110 2
before A, thread  110 2
after A, thread  110 3
before B, thread  110 3
after B, thread  110 4
before A, thread  110 4
after A, thread  110 5
before B, thread  110 5
after B, thread  110 6
before A, thread  110 6
after A, thread  110 7
before B, thread  110 7
after B, thread  110 8
before A, thread  110 8
after A, thread  110 9
before B, thread  110 9
after B, thread  110 10
before A, thread  110 10
after A, thread  110 11
before B, thread  110 11
after B, thread  110 12
110  done
[[1. 1.]]
before A, thread  192 0
after A, thread  192 1
before B, thread  192 1
after B, thread  192 2
before A, thread  192 2
after A, thread  192 3
before B, thread  192 3
after B, thread  192 4
before A, thread  192 4
after A, thread  192 5
before B, thread  192 5
after B, thread  192 6
before A, thread  192 6
after A, thread  192 7
before B, thread  192 7
after B, thread  192 8
before A, thread  192 8
after A, thread  192 9
before B, thread  192 9
after B, thread  192 10
before A, thread  192 10
after A, thread  192 11
before B, thread  192 11
after B, thread  192 12
192  done
[[1. 1.]]
before A, thread  5 0
after A, thread  5 1
before B, thread  5 1
after B, thread  5 2
before A, thread  5 2
after A, thread  5 3
before B, thread  5 3
after B, thread  5 4
before A, thread  5 4
after A, thread  5 5
before B, thread  5 5
after B, thread  5 6
before A, thread  5 6
after A, thread  5 7
before B, thread  5 7
after B, thread  5 8
before A, thread  5 8
after A, thread  5 9
before B, thread  5 9
after B, thread  5 10
before A, thread  5 10
after A, thread  5 11
before B, thread  5 11
after B, thread  5 12
5  done
[[1. 1.]]
before A, thread  179 0
after A, thread  179 1
before B, thread  179 1
after B, thread  179 2
before A, thread  179 2
after A, thread  179 3
before B, thread  179 3
after B, thread  179 4
before A, thread  179 4
after A, thread  179 5
before B, thread  179 5
after B, thread  179 6
before A, thread  179 6
after A, thread  179 7
before B, thread  179 7
after B, thread  179 8
before A, thread  179 8
after A, thread  179 9
before B, thread  179 9
after B, thread  179 10
before A, thread  179 10
after A, thread  179 11
before B, thread  179 11
after B, thread  179 12
179  done
[[1. 1.]]
before A, thread  93 0
after A, thread  93 1
before B, thread  93 1
after B, thread  93 2
before A, thread  93 2
after A, thread  93 3
before B, thread  93 3
after B, thread  93 4
before A, thread  93 4
after A, thread  93 5
before B, thread  93 5
after B, thread  93 6
before A, thread  93 6
after A, thread  93 7
before B, thread  93 7
after B, thread  93 8
before A, thread  93 8
after A, thread  93 9
before B, thread  93 9
after B, thread  93 10
before A, thread  93 10
after A, thread  93 11
before B, thread  93 11
after B, thread  93 12
93  done
[[1. 1.]]
before A, thread  146 0
after A, thread  146 1
before B, thread  146 1
after B, thread  146 2
before A, thread  146 2
after A, thread  146 3
before B, thread  146 3
after B, thread  146 4
before A, thread  146 4
after A, thread  146 5
before B, thread  146 5
after B, thread  146 6
before A, thread  146 6
after A, thread  146 7
before B, thread  146 7
after B, thread  146 8
before A, thread  146 8
after A, thread  146 9
before B, thread  146 9
after B, thread  146 10
before A, thread  146 10
after A, thread  146 11
before B, thread  146 11
after B, thread  146 12
146  done
[[1. 1.]]
before A, thread  174 0
after A, thread  174 1
before B, thread  174 1
after B, thread  174 2
before A, thread  174 2
after A, thread  174 3
before B, thread  174 3
after B, thread  174 4
before A, thread  174 4
after A, thread  174 5
before B, thread  174 5
after B, thread  174 6
before A, thread  174 6
after A, thread  174 7
before B, thread  174 7
after B, thread  174 8
before A, thread  174 8
after A, thread  174 9
before B, thread  174 9
after B, thread  174 10
before A, thread  174 10
after A, thread  174 11
before B, thread  174 11
after B, thread  174 12
174  done
[[1. 1.]]
before A, thread  22 0
after A, thread  22 1
before B, thread  22 1
after B, thread  22 2
before A, thread  22 2
after A, thread  22 3
before B, thread  22 3
after B, thread  22 4
before A, thread  22 4
after A, thread  22 5
before B, thread  22 5
after B, thread  22 6
before A, thread  22 6
after A, thread  22 7
before B, thread  22 7
after B, thread  22 8
before A, thread  22 8
after A, thread  22 9
before B, thread  22 9
after B, thread  22 10
before A, thread  22 10
after A, thread  22 11
before B, thread  22 11
after B, thread  22 12
22  done
[[1. 1.]]
before A, thread  74 0
after A, thread  74 1
before B, thread  74 1
after B, thread  74 2
before A, thread  74 2
after A, thread  74 3
before B, thread  74 3
after B, thread  74 4
before A, thread  74 4
after A, thread  74 5
before B, thread  74 5
after B, thread  74 6
before A, thread  74 6
after A, thread  74 7
before B, thread  74 7
after B, thread  74 8
before A, thread  74 8
after A, thread  74 9
before B, thread  74 9
after B, thread  74 10
before A, thread  74 10
after A, thread  74 11
before B, thread  74 11
after B, thread  74 12
74  done
[[1. 1.]]
before A, thread  144 0
after A, thread  144 1
before B, thread  144 1
after B, thread  144 2
before A, thread  144 2
after A, thread  144 3
before B, thread  144 3
after B, thread  144 4
before A, thread  144 4
after A, thread  144 5
before B, thread  144 5
after B, thread  144 6
before A, thread  144 6
after A, thread  144 7
before B, thread  144 7
after B, thread  144 8
before A, thread  144 8
after A, thread  144 9
before B, thread  144 9
after B, thread  144 10
before A, thread  144 10
after A, thread  144 11
before B, thread  144 11
after B, thread  144 12
144  done
[[1. 1.]]
before A, thread  131 0
after A, thread  131 1
before B, thread  131 1
after B, thread  131 2
before A, thread  131 2
after A, thread  131 3
before B, thread  131 3
after B, thread  131 4
before A, thread  131 4
after A, thread  131 5
before B, thread  131 5
after B, thread  131 6
before A, thread  131 6
after A, thread  131 7
before B, thread  131 7
after B, thread  131 8
before A, thread  131 8
after A, thread  131 9
before B, thread  131 9
after B, thread  131 10
before A, thread  131 10
after A, thread  131 11
before B, thread  131 11
after B, thread  131 12
131  done
[[1. 1.]]
before A, thread  10 0
after A, thread  10 1
before B, thread  10 1
after B, thread  10 2
before A, thread  10 2
after A, thread  10 3
before B, thread  10 3
after B, thread  10 4
before A, thread  10 4
after A, thread  10 5
before B, thread  10 5
after B, thread  10 6
before A, thread  10 6
after A, thread  10 7
before B, thread  10 7
after B, thread  10 8
before A, thread  10 8
after A, thread  10 9
before B, thread  10 9
after B, thread  10 10
before A, thread  10 10
after A, thread  10 11
before B, thread  10 11
after B, thread  10 12
10  done
[[1. 1.]]
before A, thread  48 0
after A, thread  48 1
before B, thread  48 1
after B, thread  48 2
before A, thread  48 2
after A, thread  48 3
before B, thread  48 3
after B, thread  48 4
before A, thread  48 4
after A, thread  48 5
before B, thread  48 5
after B, thread  48 6
before A, thread  48 6
after A, thread  48 7
before B, thread  48 7
after B, thread  48 8
before A, thread  48 8
after A, thread  48 9
before B, thread  48 9
after B, thread  48 10
before A, thread  48 10
after A, thread  48 11
before B, thread  48 11
after B, thread  48 12
48  done
[[1. 1.]]
before A, thread  78 0
after A, thread  78 1
before B, thread  78 1
after B, thread  78 2
before A, thread  78 2
after A, thread  78 3
before B, thread  78 3
after B, thread  78 4
before A, thread  78 4
after A, thread  78 5
before B, thread  78 5
after B, thread  78 6
before A, thread  78 6
after A, thread  78 7
before B, thread  78 7
after B, thread  78 8
before A, thread  78 8
after A, thread  78 9
before B, thread  78 9
after B, thread  78 10
before A, thread  78 10
after A, thread  78 11
before B, thread  78 11
after B, thread  78 12
78  done
[[1. 1.]]
before A, thread  141 0
after A, thread  141 1
before B, thread  141 1
after B, thread  141 2
before A, thread  141 2
after A, thread  141 3
before B, thread  141 3
after B, thread  141 4
before A, thread  141 4
after A, thread  141 5
before B, thread  141 5
after B, thread  141 6
before A, thread  141 6
after A, thread  141 7
before B, thread  141 7
after B, thread  141 8
before A, thread  141 8
after A, thread  141 9
before B, thread  141 9
after B, thread  141 10
before A, thread  141 10
after A, thread  141 11
before B, thread  141 11
after B, thread  141 12
141  done
[[1. 1.]]
before A, thread  16 0
after A, thread  16 1
before B, thread  16 1
after B, thread  16 2
before A, thread  16 2
after A, thread  16 3
before B, thread  16 3
after B, thread  16 4
before A, thread  16 4
after A, thread  16 5
before B, thread  16 5
after B, thread  16 6
before A, thread  16 6
after A, thread  16 7
before B, thread  16 7
after B, thread  16 8
before A, thread  16 8
after A, thread  16 9
before B, thread  16 9
after B, thread  16 10
before A, thread  16 10
after A, thread  16 11
before B, thread  16 11
after B, thread  16 12
16  done
[[1. 1.]]
before A, thread  210 0
after A, thread  210 1
before B, thread  210 1
after B, thread  210 2
before A, thread  210 2
after A, thread  210 3
before B, thread  210 3
after B, thread  210 4
before A, thread  210 4
after A, thread  210 5
before B, thread  210 5
after B, thread  210 6
before A, thread  210 6
after A, thread  210 7
before B, thread  210 7
after B, thread  210 8
before A, thread  210 8
after A, thread  210 9
before B, thread  210 9
after B, thread  210 10
before A, thread  210 10
after A, thread  210 11
before B, thread  210 11
after B, thread  210 12
210  done
[[1. 1.]]
before A, thread  25 0
after A, thread  25 1
before B, thread  25 1
after B, thread  25 2
before A, thread  25 2
after A, thread  25 3
before B, thread  25 3
after B, thread  25 4
before A, thread  25 4
after A, thread  25 5
before B, thread  25 5
after B, thread  25 6
before A, thread  25 6
after A, thread  25 7
before B, thread  25 7
after B, thread  25 8
before A, thread  25 8
after A, thread  25 9
before B, thread  25 9
after B, thread  25 10
before A, thread  25 10
after A, thread  25 11
before B, thread  25 11
after B, thread  25 12
25  done
[[1. 1.]]
before A, thread  13 0
after A, thread  13 1
before B, thread  13 1
after B, thread  13 2
before A, thread  13 2
after A, thread  13 3
before B, thread  13 3
after B, thread  13 4
before A, thread  13 4
after A, thread  13 5
before B, thread  13 5
after B, thread  13 6
before A, thread  13 6
after A, thread  13 7
before B, thread  13 7
after B, thread  13 8
before A, thread  13 8
after A, thread  13 9
before B, thread  13 9
after B, thread  13 10
before A, thread  13 10
after A, thread  13 11
before B, thread  13 11
after B, thread  13 12
13  done
[[1. 1.]]
before A, thread  198 0
after A, thread  198 1
before B, thread  198 1
after B, thread  198 2
before A, thread  198 2
after A, thread  198 3
before B, thread  198 3
after B, thread  198 4
before A, thread  198 4
after A, thread  198 5
before B, thread  198 5
after B, thread  198 6
before A, thread  198 6
after A, thread  198 7
before B, thread  198 7
after B, thread  198 8
before A, thread  198 8
after A, thread  198 9
before B, thread  198 9
after B, thread  198 10
before A, thread  198 10
after A, thread  198 11
before B, thread  198 11
after B, thread  198 12
198  done
[[1. 1.]]
before A, thread  114 0
after A, thread  114 1
before B, thread  114 1
after B, thread  114 2
before A, thread  114 2
after A, thread  114 3
before B, thread  114 3
after B, thread  114 4
before A, thread  114 4
after A, thread  114 5
before B, thread  114 5
after B, thread  114 6
before A, thread  114 6
after A, thread  114 7
before B, thread  114 7
after B, thread  114 8
before A, thread  114 8
after A, thread  114 9
before B, thread  114 9
after B, thread  114 10
before A, thread  114 10
after A, thread  114 11
before B, thread  114 11
after B, thread  114 12
114  done
[[1. 1.]]
before A, thread  150 0
after A, thread  150 1
before B, thread  150 1
after B, thread  150 2
before A, thread  150 2
after A, thread  150 3
before B, thread  150 3
after B, thread  150 4
before A, thread  150 4
after A, thread  150 5
before B, thread  150 5
after B, thread  150 6
before A, thread  150 6
after A, thread  150 7
before B, thread  150 7
after B, thread  150 8
before A, thread  150 8
after A, thread  150 9
before B, thread  150 9
after B, thread  150 10
before A, thread  150 10
after A, thread  150 11
before B, thread  150 11
after B, thread  150 12
150  done
[[1. 1.]]
before A, thread  80 0
after A, thread  80 1
before B, thread  80 1
after B, thread  80 2
before A, thread  80 2
after A, thread  80 3
before B, thread  80 3
after B, thread  80 4
before A, thread  80 4
after A, thread  80 5
before B, thread  80 5
after B, thread  80 6
before A, thread  80 6
after A, thread  80 7
before B, thread  80 7
after B, thread  80 8
before A, thread  80 8
after A, thread  80 9
before B, thread  80 9
after B, thread  80 10
before A, thread  80 10
after A, thread  80 11
before B, thread  80 11
after B, thread  80 12
80  done
[[1. 1.]]
before A, thread  41 0
after A, thread  41 1
before B, thread  41 1
after B, thread  41 2
before A, thread  41 2
after A, thread  41 3
before B, thread  41 3
after B, thread  41 4
before A, thread  41 4
after A, thread  41 5
before B, thread  41 5
after B, thread  41 6
before A, thread  41 6
after A, thread  41 7
before B, thread  41 7
after B, thread  41 8
before A, thread  41 8
after A, thread  41 9
before B, thread  41 9
after B, thread  41 10
before A, thread  41 10
after A, thread  41 11
before B, thread  41 11
after B, thread  41 12
41  done
[[1. 1.]]
before A, thread  105 0
after A, thread  105 1
before B, thread  105 1
after B, thread  105 2
before A, thread  105 2
after A, thread  105 3
before B, thread  105 3
after B, thread  105 4
before A, thread  105 4
after A, thread  105 5
before B, thread  105 5
after B, thread  105 6
before A, thread  105 6
after A, thread  105 7
before B, thread  105 7
after B, thread  105 8
before A, thread  105 8
after A, thread  105 9
before B, thread  105 9
after B, thread  105 10
before A, thread  105 10
after A, thread  105 11
before B, thread  105 11
after B, thread  105 12
105  done
[[1. 1.]]
before A, thread  56 0
after A, thread  56 1
before B, thread  56 1
after B, thread  56 2
before A, thread  56 2
after A, thread  56 3
before B, thread  56 3
after B, thread  56 4
before A, thread  56 4
after A, thread  56 5
before B, thread  56 5
after B, thread  56 6
before A, thread  56 6
after A, thread  56 7
before B, thread  56 7
after B, thread  56 8
before A, thread  56 8
after A, thread  56 9
before B, thread  56 9
after B, thread  56 10
before A, thread  56 10
after A, thread  56 11
before B, thread  56 11
after B, thread  56 12
56  done
[[1. 1.]]
before A, thread  107 0
after A, thread  107 1
before B, thread  107 1
after B, thread  107 2
before A, thread  107 2
after A, thread  107 3
before B, thread  107 3
after B, thread  107 4
before A, thread  107 4
after A, thread  107 5
before B, thread  107 5
after B, thread  107 6
before A, thread  107 6
after A, thread  107 7
before B, thread  107 7
after B, thread  107 8
before A, thread  107 8
after A, thread  107 9
before B, thread  107 9
after B, thread  107 10
before A, thread  107 10
after A, thread  107 11
before B, thread  107 11
after B, thread  107 12
107  done
[[1. 1.]]
before A, thread  160 0
after A, thread  160 1
before B, thread  160 1
after B, thread  160 2
before A, thread  160 2
after A, thread  160 3
before B, thread  160 3
after B, thread  160 4
before A, thread  160 4
after A, thread  160 5
before B, thread  160 5
after B, thread  160 6
before A, thread  160 6
after A, thread  160 7
before B, thread  160 7
after B, thread  160 8
before A, thread  160 8
after A, thread  160 9
before B, thread  160 9
after B, thread  160 10
before A, thread  160 10
after A, thread  160 11
before B, thread  160 11
after B, thread  160 12
160  done
[[1. 1.]]
before A, thread  54 0
after A, thread  54 1
before B, thread  54 1
after B, thread  54 2
before A, thread  54 2
after A, thread  54 3
before B, thread  54 3
after B, thread  54 4
before A, thread  54 4
after A, thread  54 5
before B, thread  54 5
after B, thread  54 6
before A, thread  54 6
after A, thread  54 7
before B, thread  54 7
after B, thread  54 8
before A, thread  54 8
after A, thread  54 9
before B, thread  54 9
after B, thread  54 10
before A, thread  54 10
after A, thread  54 11
before B, thread  54 11
after B, thread  54 12
54  done
[[1. 1.]]
before A, thread  98 0
after A, thread  98 1
before B, thread  98 1
after B, thread  98 2
before A, thread  98 2
after A, thread  98 3
before B, thread  98 3
after B, thread  98 4
before A, thread  98 4
after A, thread  98 5
before B, thread  98 5
after B, thread  98 6
before A, thread  98 6
after A, thread  98 7
before B, thread  98 7
after B, thread  98 8
before A, thread  98 8
after A, thread  98 9
before B, thread  98 9
after B, thread  98 10
before A, thread  98 10
after A, thread  98 11
before B, thread  98 11
after B, thread  98 12
98  done
[[1. 1.]]
before A, thread  49 0
after A, thread  49 1
before B, thread  49 1
after B, thread  49 2
before A, thread  49 2
after A, thread  49 3
before B, thread  49 3
after B, thread  49 4
before A, thread  49 4
after A, thread  49 5
before B, thread  49 5
after B, thread  49 6
before A, thread  49 6
after A, thread  49 7
before B, thread  49 7
after B, thread  49 8
before A, thread  49 8
after A, thread  49 9
before B, thread  49 9
after B, thread  49 10
before A, thread  49 10
after A, thread  49 11
before B, thread  49 11
after B, thread  49 12
49  done
[[1. 1.]]
before A, thread  21 0
after A, thread  21 1
before B, thread  21 1
after B, thread  21 2
before A, thread  21 2
after A, thread  21 3
before B, thread  21 3
after B, thread  21 4
before A, thread  21 4
after A, thread  21 5
before B, thread  21 5
after B, thread  21 6
before A, thread  21 6
after A, thread  21 7
before B, thread  21 7
after B, thread  21 8
before A, thread  21 8
after A, thread  21 9
before B, thread  21 9
after B, thread  21 10
before A, thread  21 10
after A, thread  21 11
before B, thread  21 11
after B, thread  21 12
21  done
[[1. 1.]]
before A, thread  91 0
after A, thread  91 1
before B, thread  91 1
after B, thread  91 2
before A, thread  91 2
after A, thread  91 3
before B, thread  91 3
after B, thread  91 4
before A, thread  91 4
after A, thread  91 5
before B, thread  91 5
after B, thread  91 6
before A, thread  91 6
after A, thread  91 7
before B, thread  91 7
after B, thread  91 8
before A, thread  91 8
after A, thread  91 9
before B, thread  91 9
after B, thread  91 10
before A, thread  91 10
after A, thread  91 11
before B, thread  91 11
after B, thread  91 12
91  done
[[1. 1.]]
before A, thread  197 0
after A, thread  197 1
before B, thread  197 1
after B, thread  197 2
before A, thread  197 2
after A, thread  197 3
before B, thread  197 3
after B, thread  197 4
before A, thread  197 4
after A, thread  197 5
before B, thread  197 5
after B, thread  197 6
before A, thread  197 6
after A, thread  197 7
before B, thread  197 7
after B, thread  197 8
before A, thread  197 8
after A, thread  197 9
before B, thread  197 9
after B, thread  197 10
before A, thread  197 10
after A, thread  197 11
before B, thread  197 11
after B, thread  197 12
197  done
[[1. 1.]]
before A, thread  85 0
after A, thread  85 1
before B, thread  85 1
after B, thread  85 2
before A, thread  85 2
after A, thread  85 3
before B, thread  85 3
after B, thread  85 4
before A, thread  85 4
after A, thread  85 5
before B, thread  85 5
after B, thread  85 6
before A, thread  85 6
after A, thread  85 7
before B, thread  85 7
after B, thread  85 8
before A, thread  85 8
after A, thread  85 9
before B, thread  85 9
after B, thread  85 10
before A, thread  85 10
after A, thread  85 11
before B, thread  85 11
after B, thread  85 12
85  done
[[1. 1.]]
before A, thread  113 0
after A, thread  113 1
before B, thread  113 1
after B, thread  113 2
before A, thread  113 2
after A, thread  113 3
before B, thread  113 3
after B, thread  113 4
before A, thread  113 4
after A, thread  113 5
before B, thread  113 5
after B, thread  113 6
before A, thread  113 6
after A, thread  113 7
before B, thread  113 7
after B, thread  113 8
before A, thread  113 8
after A, thread  113 9
before B, thread  113 9
after B, thread  113 10
before A, thread  113 10
after A, thread  113 11
before B, thread  113 11
after B, thread  113 12
113  done
[[1. 1.]]
before A, thread  103 0
after A, thread  103 1
before B, thread  103 1
after B, thread  103 2
before A, thread  103 2
after A, thread  103 3
before B, thread  103 3
after B, thread  103 4
before A, thread  103 4
after A, thread  103 5
before B, thread  103 5
after B, thread  103 6
before A, thread  103 6
after A, thread  103 7
before B, thread  103 7
after B, thread  103 8
before A, thread  103 8
after A, thread  103 9
before B, thread  103 9
after B, thread  103 10
before A, thread  103 10
after A, thread  103 11
before B, thread  103 11
after B, thread  103 12
103  done
[[1. 1.]]
before A, thread  223 0
after A, thread  223 1
before B, thread  223 1
after B, thread  223 2
before A, thread  223 2
after A, thread  223 3
before B, thread  223 3
after B, thread  223 4
before A, thread  223 4
after A, thread  223 5
before B, thread  223 5
after B, thread  223 6
before A, thread  223 6
after A, thread  223 7
before B, thread  223 7
after B, thread  223 8
before A, thread  223 8
after A, thread  223 9
before B, thread  223 9
after B, thread  223 10
before A, thread  223 10
after A, thread  223 11
before B, thread  223 11
after B, thread  223 12
223  done
[[1. 1.]]
before A, thread  35 0
after A, thread  35 1
before B, thread  35 1
after B, thread  35 2
before A, thread  35 2
after A, thread  35 3
before B, thread  35 3
after B, thread  35 4
before A, thread  35 4
after A, thread  35 5
before B, thread  35 5
after B, thread  35 6
before A, thread  35 6
after A, thread  35 7
before B, thread  35 7
after B, thread  35 8
before A, thread  35 8
after A, thread  35 9
before B, thread  35 9
after B, thread  35 10
before A, thread  35 10
after A, thread  35 11
before B, thread  35 11
after B, thread  35 12
35  done
[[1. 1.]]
before A, thread  165 0
after A, thread  165 1
before B, thread  165 1
after B, thread  165 2
before A, thread  165 2
after A, thread  165 3
before B, thread  165 3
after B, thread  165 4
before A, thread  165 4
after A, thread  165 5
before B, thread  165 5
after B, thread  165 6
before A, thread  165 6
after A, thread  165 7
before B, thread  165 7
after B, thread  165 8
before A, thread  165 8
after A, thread  165 9
before B, thread  165 9
after B, thread  165 10
before A, thread  165 10
after A, thread  165 11
before B, thread  165 11
after B, thread  165 12
165  done
[[1. 1.]]
before A, thread  47 0
after A, thread  47 1
before B, thread  47 1
after B, thread  47 2
before A, thread  47 2
after A, thread  47 3
before B, thread  47 3
after B, thread  47 4
before A, thread  47 4
after A, thread  47 5
before B, thread  47 5
after B, thread  47 6
before A, thread  47 6
after A, thread  47 7
before B, thread  47 7
after B, thread  47 8
before A, thread  47 8
after A, thread  47 9
before B, thread  47 9
after B, thread  47 10
before A, thread  47 10
after A, thread  47 11
before B, thread  47 11
after B, thread  47 12
47  done
[[1. 1.]]
before A, thread  158 0
after A, thread  158 1
before B, thread  158 1
after B, thread  158 2
before A, thread  158 2
after A, thread  158 3
before B, thread  158 3
after B, thread  158 4
before A, thread  158 4
after A, thread  158 5
before B, thread  158 5
after B, thread  158 6
before A, thread  158 6
after A, thread  158 7
before B, thread  158 7
after B, thread  158 8
before A, thread  158 8
after A, thread  158 9
before B, thread  158 9
after B, thread  158 10
before A, thread  158 10
after A, thread  158 11
before B, thread  158 11
after B, thread  158 12
158  done
[[1. 1.]]
before A, thread  112 0
after A, thread  112 1
before B, thread  112 1
after B, thread  112 2
before A, thread  112 2
after A, thread  112 3
before B, thread  112 3
after B, thread  112 4
before A, thread  112 4
after A, thread  112 5
before B, thread  112 5
after B, thread  112 6
before A, thread  112 6
after A, thread  112 7
before B, thread  112 7
after B, thread  112 8
before A, thread  112 8
after A, thread  112 9
before B, thread  112 9
after B, thread  112 10
before A, thread  112 10
after A, thread  112 11
before B, thread  112 11
after B, thread  112 12
112  done
[[1. 1.]]
before A, thread  92 0
after A, thread  92 1
before B, thread  92 1
after B, thread  92 2
before A, thread  92 2
after A, thread  92 3
before B, thread  92 3
after B, thread  92 4
before A, thread  92 4
after A, thread  92 5
before B, thread  92 5
after B, thread  92 6
before A, thread  92 6
after A, thread  92 7
before B, thread  92 7
after B, thread  92 8
before A, thread  92 8
after A, thread  92 9
before B, thread  92 9
after B, thread  92 10
before A, thread  92 10
after A, thread  92 11
before B, thread  92 11
after B, thread  92 12
92  done
[[1. 1.]]
before A, thread  132 0
after A, thread  132 1
before B, thread  132 1
after B, thread  132 2
before A, thread  132 2
after A, thread  132 3
before B, thread  132 3
after B, thread  132 4
before A, thread  132 4
after A, thread  132 5
before B, thread  132 5
after B, thread  132 6
before A, thread  132 6
after A, thread  132 7
before B, thread  132 7
after B, thread  132 8
before A, thread  132 8
after A, thread  132 9
before B, thread  132 9
after B, thread  132 10
before A, thread  132 10
after A, thread  132 11
before B, thread  132 11
after B, thread  132 12
132  done
[[1. 1.]]
before A, thread  18 0
after A, thread  18 1
before B, thread  18 1
after B, thread  18 2
before A, thread  18 2
after A, thread  18 3
before B, thread  18 3
after B, thread  18 4
before A, thread  18 4
after A, thread  18 5
before B, thread  18 5
after B, thread  18 6
before A, thread  18 6
after A, thread  18 7
before B, thread  18 7
after B, thread  18 8
before A, thread  18 8
after A, thread  18 9
before B, thread  18 9
after B, thread  18 10
before A, thread  18 10
after A, thread  18 11
before B, thread  18 11
after B, thread  18 12
18  done
[[1. 1.]]
before A, thread  86 0
after A, thread  86 1
before B, thread  86 1
after B, thread  86 2
before A, thread  86 2
after A, thread  86 3
before B, thread  86 3
after B, thread  86 4
before A, thread  86 4
after A, thread  86 5
before B, thread  86 5
after B, thread  86 6
before A, thread  86 6
after A, thread  86 7
before B, thread  86 7
after B, thread  86 8
before A, thread  86 8
after A, thread  86 9
before B, thread  86 9
after B, thread  86 10
before A, thread  86 10
after A, thread  86 11
before B, thread  86 11
after B, thread  86 12
86  done
[[1. 1.]]
before A, thread  148 0
after A, thread  148 1
before B, thread  148 1
after B, thread  148 2
before A, thread  148 2
after A, thread  148 3
before B, thread  148 3
after B, thread  148 4
before A, thread  148 4
after A, thread  148 5
before B, thread  148 5
after B, thread  148 6
before A, thread  148 6
after A, thread  148 7
before B, thread  148 7
after B, thread  148 8
before A, thread  148 8
after A, thread  148 9
before B, thread  148 9
after B, thread  148 10
before A, thread  148 10
after A, thread  148 11
before B, thread  148 11
after B, thread  148 12
148  done
[[1. 1.]]
before A, thread  162 0
after A, thread  162 1
before B, thread  162 1
after B, thread  162 2
before A, thread  162 2
after A, thread  162 3
before B, thread  162 3
after B, thread  162 4
before A, thread  162 4
after A, thread  162 5
before B, thread  162 5
after B, thread  162 6
before A, thread  162 6
after A, thread  162 7
before B, thread  162 7
after B, thread  162 8
before A, thread  162 8
after A, thread  162 9
before B, thread  162 9
after B, thread  162 10
before A, thread  162 10
after A, thread  162 11
before B, thread  162 11
after B, thread  162 12
162  done
[[1. 1.]]
before A, thread  3 0
after A, thread  3 1
before B, thread  3 1
after B, thread  3 2
before A, thread  3 2
after A, thread  3 3
before B, thread  3 3
after B, thread  3 4
before A, thread  3 4
after A, thread  3 5
before B, thread  3 5
after B, thread  3 6
before A, thread  3 6
after A, thread  3 7
before B, thread  3 7
after B, thread  3 8
before A, thread  3 8
after A, thread  3 9
before B, thread  3 9
after B, thread  3 10
before A, thread  3 10
after A, thread  3 11
before B, thread  3 11
after B, thread  3 12
3  done
[[1. 1.]]
before A, thread  118 0
after A, thread  118 1
before B, thread  118 1
after B, thread  118 2
before A, thread  118 2
after A, thread  118 3
before B, thread  118 3
after B, thread  118 4
before A, thread  118 4
after A, thread  118 5
before B, thread  118 5
after B, thread  118 6
before A, thread  118 6
after A, thread  118 7
before B, thread  118 7
after B, thread  118 8
before A, thread  118 8
after A, thread  118 9
before B, thread  118 9
after B, thread  118 10
before A, thread  118 10
after A, thread  118 11
before B, thread  118 11
after B, thread  118 12
118  done
[[1. 1.]]
before A, thread  32 0
after A, thread  32 1
before B, thread  32 1
after B, thread  32 2
before A, thread  32 2
after A, thread  32 3
before B, thread  32 3
after B, thread  32 4
before A, thread  32 4
after A, thread  32 5
before B, thread  32 5
after B, thread  32 6
before A, thread  32 6
after A, thread  32 7
before B, thread  32 7
after B, thread  32 8
before A, thread  32 8
after A, thread  32 9
before B, thread  32 9
after B, thread  32 10
before A, thread  32 10
after A, thread  32 11
before B, thread  32 11
after B, thread  32 12
32  done
[[1. 1.]]
before A, thread  155 0
after A, thread  155 1
before B, thread  155 1
after B, thread  155 2
before A, thread  155 2
after A, thread  155 3
before B, thread  155 3
after B, thread  155 4
before A, thread  155 4
after A, thread  155 5
before B, thread  155 5
after B, thread  155 6
before A, thread  155 6
after A, thread  155 7
before B, thread  155 7
after B, thread  155 8
before A, thread  155 8
after A, thread  155 9
before B, thread  155 9
after B, thread  155 10
before A, thread  155 10
after A, thread  155 11
before B, thread  155 11
after B, thread  155 12
155  done
[[1. 1.]]
before A, thread  229 0
after A, thread  229 1
before B, thread  229 1
after B, thread  229 2
before A, thread  229 2
after A, thread  229 3
before B, thread  229 3
after B, thread  229 4
before A, thread  229 4
after A, thread  229 5
before B, thread  229 5
after B, thread  229 6
before A, thread  229 6
after A, thread  229 7
before B, thread  229 7
after B, thread  229 8
before A, thread  229 8
after A, thread  229 9
before B, thread  229 9
after B, thread  229 10
before A, thread  229 10
after A, thread  229 11
before B, thread  229 11
after B, thread  229 12
229  done
[[1. 1.]]
before A, thread  79 0
after A, thread  79 1
before B, thread  79 1
after B, thread  79 2
before A, thread  79 2
after A, thread  79 3
before B, thread  79 3
after B, thread  79 4
before A, thread  79 4
after A, thread  79 5
before B, thread  79 5
after B, thread  79 6
before A, thread  79 6
after A, thread  79 7
before B, thread  79 7
after B, thread  79 8
before A, thread  79 8
after A, thread  79 9
before B, thread  79 9
after B, thread  79 10
before A, thread  79 10
after A, thread  79 11
before B, thread  79 11
after B, thread  79 12
79  done
[[1. 1.]]
before A, thread  128 0
after A, thread  128 1
before B, thread  128 1
after B, thread  128 2
before A, thread  128 2
after A, thread  128 3
before B, thread  128 3
after B, thread  128 4
before A, thread  128 4
after A, thread  128 5
before B, thread  128 5
after B, thread  128 6
before A, thread  128 6
after A, thread  128 7
before B, thread  128 7
after B, thread  128 8
before A, thread  128 8
after A, thread  128 9
before B, thread  128 9
after B, thread  128 10
before A, thread  128 10
after A, thread  128 11
before B, thread  128 11
after B, thread  128 12
128  done
[[1. 1.]]
before A, thread  87 0
after A, thread  87 1
before B, thread  87 1
after B, thread  87 2
before A, thread  87 2
after A, thread  87 3
before B, thread  87 3
after B, thread  87 4
before A, thread  87 4
after A, thread  87 5
before B, thread  87 5
after B, thread  87 6
before A, thread  87 6
after A, thread  87 7
before B, thread  87 7
after B, thread  87 8
before A, thread  87 8
after A, thread  87 9
before B, thread  87 9
after B, thread  87 10
before A, thread  87 10
after A, thread  87 11
before B, thread  87 11
after B, thread  87 12
87  done
[[1. 1.]]
before A, thread  142 0
after A, thread  142 1
before B, thread  142 1
after B, thread  142 2
before A, thread  142 2
after A, thread  142 3
before B, thread  142 3
after B, thread  142 4
before A, thread  142 4
after A, thread  142 5
before B, thread  142 5
after B, thread  142 6
before A, thread  142 6
after A, thread  142 7
before B, thread  142 7
after B, thread  142 8
before A, thread  142 8
after A, thread  142 9
before B, thread  142 9
after B, thread  142 10
before A, thread  142 10
after A, thread  142 11
before B, thread  142 11
after B, thread  142 12
142  done
[[1. 1.]]
before A, thread  100 0
after A, thread  100 1
before B, thread  100 1
after B, thread  100 2
before A, thread  100 2
after A, thread  100 3
before B, thread  100 3
after B, thread  100 4
before A, thread  100 4
after A, thread  100 5
before B, thread  100 5
after B, thread  100 6
before A, thread  100 6
after A, thread  100 7
before B, thread  100 7
after B, thread  100 8
before A, thread  100 8
after A, thread  100 9
before B, thread  100 9
after B, thread  100 10
before A, thread  100 10
after A, thread  100 11
before B, thread  100 11
after B, thread  100 12
100  done
[[1. 1.]]
before A, thread  84 0
after A, thread  84 1
before B, thread  84 1
after B, thread  84 2
before A, thread  84 2
after A, thread  84 3
before B, thread  84 3
after B, thread  84 4
before A, thread  84 4
after A, thread  84 5
before B, thread  84 5
after B, thread  84 6
before A, thread  84 6
after A, thread  84 7
before B, thread  84 7
after B, thread  84 8
before A, thread  84 8
after A, thread  84 9
before B, thread  84 9
after B, thread  84 10
before A, thread  84 10
after A, thread  84 11
before B, thread  84 11
after B, thread  84 12
84  done
[[1. 1.]]
before A, thread  156 0
after A, thread  156 1
before B, thread  156 1
after B, thread  156 2
before A, thread  156 2
after A, thread  156 3
before B, thread  156 3
after B, thread  156 4
before A, thread  156 4
after A, thread  156 5
before B, thread  156 5
after B, thread  156 6
before A, thread  156 6
after A, thread  156 7
before B, thread  156 7
after B, thread  156 8
before A, thread  156 8
after A, thread  156 9
before B, thread  156 9
after B, thread  156 10
before A, thread  156 10
after A, thread  156 11
before B, thread  156 11
after B, thread  156 12
156  done
[[1. 1.]]
before A, thread  33 0
after A, thread  33 1
before B, thread  33 1
after B, thread  33 2
before A, thread  33 2
after A, thread  33 3
before B, thread  33 3
after B, thread  33 4
before A, thread  33 4
after A, thread  33 5
before B, thread  33 5
after B, thread  33 6
before A, thread  33 6
after A, thread  33 7
before B, thread  33 7
after B, thread  33 8
before A, thread  33 8
after A, thread  33 9
before B, thread  33 9
after B, thread  33 10
before A, thread  33 10
after A, thread  33 11
before B, thread  33 11
after B, thread  33 12
33  done
[[1. 1.]]
before A, thread  227 0
after A, thread  227 1
before B, thread  227 1
after B, thread  227 2
before A, thread  227 2
after A, thread  227 3
before B, thread  227 3
after B, thread  227 4
before A, thread  227 4
after A, thread  227 5
before B, thread  227 5
after B, thread  227 6
before A, thread  227 6
after A, thread  227 7
before B, thread  227 7
after B, thread  227 8
before A, thread  227 8
after A, thread  227 9
before B, thread  227 9
after B, thread  227 10
before A, thread  227 10
after A, thread  227 11
before B, thread  227 11
after B, thread  227 12
227  done
[[1. 1.]]
before A, thread  46 0
after A, thread  46 1
before B, thread  46 1
after B, thread  46 2
before A, thread  46 2
after A, thread  46 3
before B, thread  46 3
after B, thread  46 4
before A, thread  46 4
after A, thread  46 5
before B, thread  46 5
after B, thread  46 6
before A, thread  46 6
after A, thread  46 7
before B, thread  46 7
after B, thread  46 8
before A, thread  46 8
after A, thread  46 9
before B, thread  46 9
after B, thread  46 10
before A, thread  46 10
after A, thread  46 11
before B, thread  46 11
after B, thread  46 12
46  done
[[1. 1.]]
before A, thread  88 0
after A, thread  88 1
before B, thread  88 1
after B, thread  88 2
before A, thread  88 2
after A, thread  88 3
before B, thread  88 3
after B, thread  88 4
before A, thread  88 4
after A, thread  88 5
before B, thread  88 5
after B, thread  88 6
before A, thread  88 6
after A, thread  88 7
before B, thread  88 7
after B, thread  88 8
before A, thread  88 8
after A, thread  88 9
before B, thread  88 9
after B, thread  88 10
before A, thread  88 10
after A, thread  88 11
before B, thread  88 11
after B, thread  88 12
88  done
[[1. 1.]]
before A, thread  75 0
after A, thread  75 1
before B, thread  75 1
after B, thread  75 2
before A, thread  75 2
after A, thread  75 3
before B, thread  75 3
after B, thread  75 4
before A, thread  75 4
after A, thread  75 5
before B, thread  75 5
after B, thread  75 6
before A, thread  75 6
after A, thread  75 7
before B, thread  75 7
after B, thread  75 8
before A, thread  75 8
after A, thread  75 9
before B, thread  75 9
after B, thread  75 10
before A, thread  75 10
after A, thread  75 11
before B, thread  75 11
after B, thread  75 12
75  done
[[1. 1.]]
before A, thread  31 0
after A, thread  31 1
before B, thread  31 1
after B, thread  31 2
before A, thread  31 2
after A, thread  31 3
before B, thread  31 3
after B, thread  31 4
before A, thread  31 4
after A, thread  31 5
before B, thread  31 5
after B, thread  31 6
before A, thread  31 6
after A, thread  31 7
before B, thread  31 7
after B, thread  31 8
before A, thread  31 8
after A, thread  31 9
before B, thread  31 9
after B, thread  31 10
before A, thread  31 10
after A, thread  31 11
before B, thread  31 11
after B, thread  31 12
31  done
[[1. 1.]]
before A, thread  19 0
after A, thread  19 1
before B, thread  19 1
after B, thread  19 2
before A, thread  19 2
after A, thread  19 3
before B, thread  19 3
after B, thread  19 4
before A, thread  19 4
after A, thread  19 5
before B, thread  19 5
after B, thread  19 6
before A, thread  19 6
after A, thread  19 7
before B, thread  19 7
after B, thread  19 8
before A, thread  19 8
after A, thread  19 9
before B, thread  19 9
after B, thread  19 10
before A, thread  19 10
after A, thread  19 11
before B, thread  19 11
after B, thread  19 12
19  done
[[1. 1.]]
before A, thread  39 0
after A, thread  39 1
before B, thread  39 1
after B, thread  39 2
before A, thread  39 2
after A, thread  39 3
before B, thread  39 3
after B, thread  39 4
before A, thread  39 4
after A, thread  39 5
before B, thread  39 5
after B, thread  39 6
before A, thread  39 6
after A, thread  39 7
before B, thread  39 7
after B, thread  39 8
before A, thread  39 8
after A, thread  39 9
before B, thread  39 9
after B, thread  39 10
before A, thread  39 10
after A, thread  39 11
before B, thread  39 11
after B, thread  39 12
39  done
[[1. 1.]]
before A, thread  66 0
after A, thread  66 1
before B, thread  66 1
after B, thread  66 2
before A, thread  66 2
after A, thread  66 3
before B, thread  66 3
after B, thread  66 4
before A, thread  66 4
after A, thread  66 5
before B, thread  66 5
after B, thread  66 6
before A, thread  66 6
after A, thread  66 7
before B, thread  66 7
after B, thread  66 8
before A, thread  66 8
after A, thread  66 9
before B, thread  66 9
after B, thread  66 10
before A, thread  66 10
after A, thread  66 11
before B, thread  66 11
after B, thread  66 12
66  done
[[1. 1.]]
before A, thread  168 0
after A, thread  168 1
before B, thread  168 1
after B, thread  168 2
before A, thread  168 2
after A, thread  168 3
before B, thread  168 3
after B, thread  168 4
before A, thread  168 4
after A, thread  168 5
before B, thread  168 5
after B, thread  168 6
before A, thread  168 6
after A, thread  168 7
before B, thread  168 7
after B, thread  168 8
before A, thread  168 8
after A, thread  168 9
before B, thread  168 9
after B, thread  168 10
before A, thread  168 10
after A, thread  168 11
before B, thread  168 11
after B, thread  168 12
168  done
[[1. 1.]]
before A, thread  187 0
after A, thread  187 1
before B, thread  187 1
after B, thread  187 2
before A, thread  187 2
after A, thread  187 3
before B, thread  187 3
after B, thread  187 4
before A, thread  187 4
after A, thread  187 5
before B, thread  187 5
after B, thread  187 6
before A, thread  187 6
after A, thread  187 7
before B, thread  187 7
after B, thread  187 8
before A, thread  187 8
after A, thread  187 9
before B, thread  187 9
after B, thread  187 10
before A, thread  187 10
after A, thread  187 11
before B, thread  187 11
after B, thread  187 12
187  done
[[1. 1.]]
before A, thread  52 0
after A, thread  52 1
before B, thread  52 1
after B, thread  52 2
before A, thread  52 2
after A, thread  52 3
before B, thread  52 3
after B, thread  52 4
before A, thread  52 4
after A, thread  52 5
before B, thread  52 5
after B, thread  52 6
before A, thread  52 6
after A, thread  52 7
before B, thread  52 7
after B, thread  52 8
before A, thread  52 8
after A, thread  52 9
before B, thread  52 9
after B, thread  52 10
before A, thread  52 10
after A, thread  52 11
before B, thread  52 11
after B, thread  52 12
52  done
[[1. 1.]]
before A, thread  51 0
after A, thread  51 1
before B, thread  51 1
after B, thread  51 2
before A, thread  51 2
after A, thread  51 3
before B, thread  51 3
after B, thread  51 4
before A, thread  51 4
after A, thread  51 5
before B, thread  51 5
after B, thread  51 6
before A, thread  51 6
after A, thread  51 7
before B, thread  51 7
after B, thread  51 8
before A, thread  51 8
after A, thread  51 9
before B, thread  51 9
after B, thread  51 10
before A, thread  51 10
after A, thread  51 11
before B, thread  51 11
after B, thread  51 12
51  done
[[1. 1.]]
before A, thread  65 0
after A, thread  65 1
before B, thread  65 1
after B, thread  65 2
before A, thread  65 2
after A, thread  65 3
before B, thread  65 3
after B, thread  65 4
before A, thread  65 4
after A, thread  65 5
before B, thread  65 5
after B, thread  65 6
before A, thread  65 6
after A, thread  65 7
before B, thread  65 7
after B, thread  65 8
before A, thread  65 8
after A, thread  65 9
before B, thread  65 9
after B, thread  65 10
before A, thread  65 10
after A, thread  65 11
before B, thread  65 11
after B, thread  65 12
65  done
[[1. 1.]]
before A, thread  199 0
after A, thread  199 1
before B, thread  199 1
after B, thread  199 2
before A, thread  199 2
after A, thread  199 3
before B, thread  199 3
after B, thread  199 4
before A, thread  199 4
after A, thread  199 5
before B, thread  199 5
after B, thread  199 6
before A, thread  199 6
after A, thread  199 7
before B, thread  199 7
after B, thread  199 8
before A, thread  199 8
after A, thread  199 9
before B, thread  199 9
after B, thread  199 10
before A, thread  199 10
after A, thread  199 11
before B, thread  199 11
after B, thread  199 12
199  done
[[1. 1.]]
before A, thread  104 0
after A, thread  104 1
before B, thread  104 1
after B, thread  104 2
before A, thread  104 2
after A, thread  104 3
before B, thread  104 3
after B, thread  104 4
before A, thread  104 4
after A, thread  104 5
before B, thread  104 5
after B, thread  104 6
before A, thread  104 6
after A, thread  104 7
before B, thread  104 7
after B, thread  104 8
before A, thread  104 8
after A, thread  104 9
before B, thread  104 9
after B, thread  104 10
before A, thread  104 10
after A, thread  104 11
before B, thread  104 11
after B, thread  104 12
104  done
[[1. 1.]]
before A, thread  136 0
after A, thread  136 1
before B, thread  136 1
after B, thread  136 2
before A, thread  136 2
after A, thread  136 3
before B, thread  136 3
after B, thread  136 4
before A, thread  136 4
after A, thread  136 5
before B, thread  136 5
after B, thread  136 6
before A, thread  136 6
after A, thread  136 7
before B, thread  136 7
after B, thread  136 8
before A, thread  136 8
after A, thread  136 9
before B, thread  136 9
after B, thread  136 10
before A, thread  136 10
after A, thread  136 11
before B, thread  136 11
after B, thread  136 12
136  done
[[1. 1.]]
before A, thread  181 0
after A, thread  181 1
before B, thread  181 1
after B, thread  181 2
before A, thread  181 2
after A, thread  181 3
before B, thread  181 3
after B, thread  181 4
before A, thread  181 4
after A, thread  181 5
before B, thread  181 5
after B, thread  181 6
before A, thread  181 6
after A, thread  181 7
before B, thread  181 7
after B, thread  181 8
before A, thread  181 8
after A, thread  181 9
before B, thread  181 9
after B, thread  181 10
before A, thread  181 10
after A, thread  181 11
before B, thread  181 11
after B, thread  181 12
181  done
[[1. 1.]]
before A, thread  238 0
after A, thread  238 1
before B, thread  238 1
after B, thread  238 2
before A, thread  238 2
after A, thread  238 3
before B, thread  238 3
after B, thread  238 4
before A, thread  238 4
after A, thread  238 5
before B, thread  238 5
after B, thread  238 6
before A, thread  238 6
after A, thread  238 7
before B, thread  238 7
after B, thread  238 8
before A, thread  238 8
after A, thread  238 9
before B, thread  238 9
after B, thread  238 10
before A, thread  238 10
after A, thread  238 11
before B, thread  238 11
after B, thread  238 12
238  done
[[1. 1.]]
before A, thread  117 0
after A, thread  117 1
before B, thread  117 1
after B, thread  117 2
before A, thread  117 2
after A, thread  117 3
before B, thread  117 3
after B, thread  117 4
before A, thread  117 4
after A, thread  117 5
before B, thread  117 5
after B, thread  117 6
before A, thread  117 6
after A, thread  117 7
before B, thread  117 7
after B, thread  117 8
before A, thread  117 8
after A, thread  117 9
before B, thread  117 9
after B, thread  117 10
before A, thread  117 10
after A, thread  117 11
before B, thread  117 11
after B, thread  117 12
117  done
[[1. 1.]]
before A, thread  173 0
after A, thread  173 1
before B, thread  173 1
after B, thread  173 2
before A, thread  173 2
after A, thread  173 3
before B, thread  173 3
after B, thread  173 4
before A, thread  173 4
after A, thread  173 5
before B, thread  173 5
after B, thread  173 6
before A, thread  173 6
after A, thread  173 7
before B, thread  173 7
after B, thread  173 8
before A, thread  173 8
after A, thread  173 9
before B, thread  173 9
after B, thread  173 10
before A, thread  173 10
after A, thread  173 11
before B, thread  173 11
after B, thread  173 12
173  done
[[1. 1.]]
before A, thread  67 0
after A, thread  67 1
before B, thread  67 1
after B, thread  67 2
before A, thread  67 2
after A, thread  67 3
before B, thread  67 3
after B, thread  67 4
before A, thread  67 4
after A, thread  67 5
before B, thread  67 5
after B, thread  67 6
before A, thread  67 6
after A, thread  67 7
before B, thread  67 7
after B, thread  67 8
before A, thread  67 8
after A, thread  67 9
before B, thread  67 9
after B, thread  67 10
before A, thread  67 10
after A, thread  67 11
before B, thread  67 11
after B, thread  67 12
67  done
[[1. 1.]]
before A, thread  101 0
after A, thread  101 1
before B, thread  101 1
after B, thread  101 2
before A, thread  101 2
after A, thread  101 3
before B, thread  101 3
after B, thread  101 4
before A, thread  101 4
after A, thread  101 5
before B, thread  101 5
after B, thread  101 6
before A, thread  101 6
after A, thread  101 7
before B, thread  101 7
after B, thread  101 8
before A, thread  101 8
after A, thread  101 9
before B, thread  101 9
after B, thread  101 10
before A, thread  101 10
after A, thread  101 11
before B, thread  101 11
after B, thread  101 12
101  done
[[1. 1.]]
before A, thread  12 0
after A, thread  12 1
before B, thread  12 1
after B, thread  12 2
before A, thread  12 2
after A, thread  12 3
before B, thread  12 3
after B, thread  12 4
before A, thread  12 4
after A, thread  12 5
before B, thread  12 5
after B, thread  12 6
before A, thread  12 6
after A, thread  12 7
before B, thread  12 7
after B, thread  12 8
before A, thread  12 8
after A, thread  12 9
before B, thread  12 9
after B, thread  12 10
before A, thread  12 10
after A, thread  12 11
before B, thread  12 11
after B, thread  12 12
12  done
[[1. 1.]]
before A, thread  241 0
after A, thread  241 1
before B, thread  241 1
after B, thread  241 2
before A, thread  241 2
after A, thread  241 3
before B, thread  241 3
after B, thread  241 4
before A, thread  241 4
after A, thread  241 5
before B, thread  241 5
after B, thread  241 6
before A, thread  241 6
after A, thread  241 7
before B, thread  241 7
after B, thread  241 8
before A, thread  241 8
after A, thread  241 9
before B, thread  241 9
after B, thread  241 10
before A, thread  241 10
after A, thread  241 11
before B, thread  241 11
after B, thread  241 12
241  done
[[1. 1.]]
before A, thread  77 0
after A, thread  77 1
before B, thread  77 1
after B, thread  77 2
before A, thread  77 2
after A, thread  77 3
before B, thread  77 3
after B, thread  77 4
before A, thread  77 4
after A, thread  77 5
before B, thread  77 5
after B, thread  77 6
before A, thread  77 6
after A, thread  77 7
before B, thread  77 7
after B, thread  77 8
before A, thread  77 8
after A, thread  77 9
before B, thread  77 9
after B, thread  77 10
before A, thread  77 10
after A, thread  77 11
before B, thread  77 11
after B, thread  77 12
77  done
[[1. 1.]]
before A, thread  172 0
after A, thread  172 1
before B, thread  172 1
after B, thread  172 2
before A, thread  172 2
after A, thread  172 3
before B, thread  172 3
after B, thread  172 4
before A, thread  172 4
after A, thread  172 5
before B, thread  172 5
after B, thread  172 6
before A, thread  172 6
after A, thread  172 7
before B, thread  172 7
after B, thread  172 8
before A, thread  172 8
after A, thread  172 9
before B, thread  172 9
after B, thread  172 10
before A, thread  172 10
after A, thread  172 11
before B, thread  172 11
after B, thread  172 12
172  done
[[1. 1.]]
before A, thread  218 0
after A, thread  218 1
before B, thread  218 1
after B, thread  218 2
before A, thread  218 2
after A, thread  218 3
before B, thread  218 3
after B, thread  218 4
before A, thread  218 4
after A, thread  218 5
before B, thread  218 5
after B, thread  218 6
before A, thread  218 6
after A, thread  218 7
before B, thread  218 7
after B, thread  218 8
before A, thread  218 8
after A, thread  218 9
before B, thread  218 9
after B, thread  218 10
before A, thread  218 10
after A, thread  218 11
before B, thread  218 11
after B, thread  218 12
218  done
[[1. 1.]]
before A, thread  143 0
after A, thread  143 1
before B, thread  143 1
after B, thread  143 2
before A, thread  143 2
after A, thread  143 3
before B, thread  143 3
after B, thread  143 4
before A, thread  143 4
after A, thread  143 5
before B, thread  143 5
after B, thread  143 6
before A, thread  143 6
after A, thread  143 7
before B, thread  143 7
after B, thread  143 8
before A, thread  143 8
after A, thread  143 9
before B, thread  143 9
after B, thread  143 10
before A, thread  143 10
after A, thread  143 11
before B, thread  143 11
after B, thread  143 12
143  done
[[1. 1.]]
before A, thread  127 0
after A, thread  127 1
before B, thread  127 1
after B, thread  127 2
before A, thread  127 2
after A, thread  127 3
before B, thread  127 3
after B, thread  127 4
before A, thread  127 4
after A, thread  127 5
before B, thread  127 5
after B, thread  127 6
before A, thread  127 6
after A, thread  127 7
before B, thread  127 7
after B, thread  127 8
before A, thread  127 8
after A, thread  127 9
before B, thread  127 9
after B, thread  127 10
before A, thread  127 10
after A, thread  127 11
before B, thread  127 11
after B, thread  127 12
127  done
[[1. 1.]]
before A, thread  134 0
after A, thread  134 1
before B, thread  134 1
after B, thread  134 2
before A, thread  134 2
after A, thread  134 3
before B, thread  134 3
after B, thread  134 4
before A, thread  134 4
after A, thread  134 5
before B, thread  134 5
after B, thread  134 6
before A, thread  134 6
after A, thread  134 7
before B, thread  134 7
after B, thread  134 8
before A, thread  134 8
after A, thread  134 9
before B, thread  134 9
after B, thread  134 10
before A, thread  134 10
after A, thread  134 11
before B, thread  134 11
after B, thread  134 12
134  done
[[1. 1.]]
before A, thread  170 0
after A, thread  170 1
before B, thread  170 1
after B, thread  170 2
before A, thread  170 2
after A, thread  170 3
before B, thread  170 3
after B, thread  170 4
before A, thread  170 4
after A, thread  170 5
before B, thread  170 5
after B, thread  170 6
before A, thread  170 6
after A, thread  170 7
before B, thread  170 7
after B, thread  170 8
before A, thread  170 8
after A, thread  170 9
before B, thread  170 9
after B, thread  170 10
before A, thread  170 10
after A, thread  170 11
before B, thread  170 11
after B, thread  170 12
170  done
[[1. 1.]]
before A, thread  161 0
after A, thread  161 1
before B, thread  161 1
after B, thread  161 2
before A, thread  161 2
after A, thread  161 3
before B, thread  161 3
after B, thread  161 4
before A, thread  161 4
after A, thread  161 5
before B, thread  161 5
after B, thread  161 6
before A, thread  161 6
after A, thread  161 7
before B, thread  161 7
after B, thread  161 8
before A, thread  161 8
after A, thread  161 9
before B, thread  161 9
after B, thread  161 10
before A, thread  161 10
after A, thread  161 11
before B, thread  161 11
after B, thread  161 12
161  done
[[1. 1.]]
before A, thread  183 0
after A, thread  183 1
before B, thread  183 1
after B, thread  183 2
before A, thread  183 2
after A, thread  183 3
before B, thread  183 3
after B, thread  183 4
before A, thread  183 4
after A, thread  183 5
before B, thread  183 5
after B, thread  183 6
before A, thread  183 6
after A, thread  183 7
before B, thread  183 7
after B, thread  183 8
before A, thread  183 8
after A, thread  183 9
before B, thread  183 9
after B, thread  183 10
before A, thread  183 10
after A, thread  183 11
before B, thread  183 11
after B, thread  183 12
183  done
[[1. 1.]]
before A, thread  111 0
after A, thread  111 1
before B, thread  111 1
after B, thread  111 2
before A, thread  111 2
after A, thread  111 3
before B, thread  111 3
after B, thread  111 4
before A, thread  111 4
after A, thread  111 5
before B, thread  111 5
after B, thread  111 6
before A, thread  111 6
after A, thread  111 7
before B, thread  111 7
after B, thread  111 8
before A, thread  111 8
after A, thread  111 9
before B, thread  111 9
after B, thread  111 10
before A, thread  111 10
after A, thread  111 11
before B, thread  111 11
after B, thread  111 12
111  done
[[1. 1.]]
before A, thread  164 0
after A, thread  164 1
before B, thread  164 1
after B, thread  164 2
before A, thread  164 2
after A, thread  164 3
before B, thread  164 3
after B, thread  164 4
before A, thread  164 4
after A, thread  164 5
before B, thread  164 5
after B, thread  164 6
before A, thread  164 6
after A, thread  164 7
before B, thread  164 7
after B, thread  164 8
before A, thread  164 8
after A, thread  164 9
before B, thread  164 9
after B, thread  164 10
before A, thread  164 10
after A, thread  164 11
before B, thread  164 11
after B, thread  164 12
164  done
[[1. 1.]]
before A, thread  116 0
after A, thread  116 1
before B, thread  116 1
after B, thread  116 2
before A, thread  116 2
after A, thread  116 3
before B, thread  116 3
after B, thread  116 4
before A, thread  116 4
after A, thread  116 5
before B, thread  116 5
after B, thread  116 6
before A, thread  116 6
after A, thread  116 7
before B, thread  116 7
after B, thread  116 8
before A, thread  116 8
after A, thread  116 9
before B, thread  116 9
after B, thread  116 10
before A, thread  116 10
after A, thread  116 11
before B, thread  116 11
after B, thread  116 12
116  done
[[1. 1.]]
before A, thread  69 0
after A, thread  69 1
before B, thread  69 1
after B, thread  69 2
before A, thread  69 2
after A, thread  69 3
before B, thread  69 3
after B, thread  69 4
before A, thread  69 4
after A, thread  69 5
before B, thread  69 5
after B, thread  69 6
before A, thread  69 6
after A, thread  69 7
before B, thread  69 7
after B, thread  69 8
before A, thread  69 8
after A, thread  69 9
before B, thread  69 9
after B, thread  69 10
before A, thread  69 10
after A, thread  69 11
before B, thread  69 11
after B, thread  69 12
69  done
[[1. 1.]]
before A, thread  119 0
after A, thread  119 1
before B, thread  119 1
after B, thread  119 2
before A, thread  119 2
after A, thread  119 3
before B, thread  119 3
after B, thread  119 4
before A, thread  119 4
after A, thread  119 5
before B, thread  119 5
after B, thread  119 6
before A, thread  119 6
after A, thread  119 7
before B, thread  119 7
after B, thread  119 8
before A, thread  119 8
after A, thread  119 9
before B, thread  119 9
after B, thread  119 10
before A, thread  119 10
after A, thread  119 11
before B, thread  119 11
after B, thread  119 12
119  done
[[1. 1.]]
before A, thread  81 0
after A, thread  81 1
before B, thread  81 1
after B, thread  81 2
before A, thread  81 2
after A, thread  81 3
before B, thread  81 3
after B, thread  81 4
before A, thread  81 4
after A, thread  81 5
before B, thread  81 5
after B, thread  81 6
before A, thread  81 6
after A, thread  81 7
before B, thread  81 7
after B, thread  81 8
before A, thread  81 8
after A, thread  81 9
before B, thread  81 9
after B, thread  81 10
before A, thread  81 10
after A, thread  81 11
before B, thread  81 11
after B, thread  81 12
81  done
[[1. 1.]]
before A, thread  147 0
after A, thread  147 1
before B, thread  147 1
after B, thread  147 2
before A, thread  147 2
after A, thread  147 3
before B, thread  147 3
after B, thread  147 4
before A, thread  147 4
after A, thread  147 5
before B, thread  147 5
after B, thread  147 6
before A, thread  147 6
after A, thread  147 7
before B, thread  147 7
after B, thread  147 8
before A, thread  147 8
after A, thread  147 9
before B, thread  147 9
after B, thread  147 10
before A, thread  147 10
after A, thread  147 11
before B, thread  147 11
after B, thread  147 12
147  done
[[1. 1.]]
before A, thread  130 0
after A, thread  130 1
before B, thread  130 1
after B, thread  130 2
before A, thread  130 2
after A, thread  130 3
before B, thread  130 3
after B, thread  130 4
before A, thread  130 4
after A, thread  130 5
before B, thread  130 5
after B, thread  130 6
before A, thread  130 6
after A, thread  130 7
before B, thread  130 7
after B, thread  130 8
before A, thread  130 8
after A, thread  130 9
before B, thread  130 9
after B, thread  130 10
before A, thread  130 10
after A, thread  130 11
before B, thread  130 11
after B, thread  130 12
130  done
[[1. 1.]]
before A, thread  163 0
after A, thread  163 1
before B, thread  163 1
after B, thread  163 2
before A, thread  163 2
after A, thread  163 3
before B, thread  163 3
after B, thread  163 4
before A, thread  163 4
after A, thread  163 5
before B, thread  163 5
after B, thread  163 6
before A, thread  163 6
after A, thread  163 7
before B, thread  163 7
after B, thread  163 8
before A, thread  163 8
after A, thread  163 9
before B, thread  163 9
after B, thread  163 10
before A, thread  163 10
after A, thread  163 11
before B, thread  163 11
after B, thread  163 12
163  done
[[1. 1.]]
before A, thread  129 0
after A, thread  129 1
before B, thread  129 1
after B, thread  129 2
before A, thread  129 2
after A, thread  129 3
before B, thread  129 3
after B, thread  129 4
before A, thread  129 4
after A, thread  129 5
before B, thread  129 5
after B, thread  129 6
before A, thread  129 6
after A, thread  129 7
before B, thread  129 7
after B, thread  129 8
before A, thread  129 8
after A, thread  129 9
before B, thread  129 9
after B, thread  129 10
before A, thread  129 10
after A, thread  129 11
before B, thread  129 11
after B, thread  129 12
129  done
[[1. 1.]]
before A, thread  58 0
after A, thread  58 1
before B, thread  58 1
after B, thread  58 2
before A, thread  58 2
after A, thread  58 3
before B, thread  58 3
after B, thread  58 4
before A, thread  58 4
after A, thread  58 5
before B, thread  58 5
after B, thread  58 6
before A, thread  58 6
after A, thread  58 7
before B, thread  58 7
after B, thread  58 8
before A, thread  58 8
after A, thread  58 9
before B, thread  58 9
after B, thread  58 10
before A, thread  58 10
after A, thread  58 11
before B, thread  58 11
after B, thread  58 12
58  done
[[1. 1.]]
before A, thread  140 0
after A, thread  140 1
before B, thread  140 1
after B, thread  140 2
before A, thread  140 2
after A, thread  140 3
before B, thread  140 3
after B, thread  140 4
before A, thread  140 4
after A, thread  140 5
before B, thread  140 5
after B, thread  140 6
before A, thread  140 6
after A, thread  140 7
before B, thread  140 7
after B, thread  140 8
before A, thread  140 8
after A, thread  140 9
before B, thread  140 9
after B, thread  140 10
before A, thread  140 10
after A, thread  140 11
before B, thread  140 11
after B, thread  140 12
140  done
[[1. 1.]]
before A, thread  89 0
after A, thread  89 1
before B, thread  89 1
after B, thread  89 2
before A, thread  89 2
after A, thread  89 3
before B, thread  89 3
after B, thread  89 4
before A, thread  89 4
after A, thread  89 5
before B, thread  89 5
after B, thread  89 6
before A, thread  89 6
after A, thread  89 7
before B, thread  89 7
after B, thread  89 8
before A, thread  89 8
after A, thread  89 9
before B, thread  89 9
after B, thread  89 10
before A, thread  89 10
after A, thread  89 11
before B, thread  89 11
after B, thread  89 12
89  done
[[1. 1.]]
before A, thread  209 0
after A, thread  209 1
before B, thread  209 1
after B, thread  209 2
before A, thread  209 2
after A, thread  209 3
before B, thread  209 3
after B, thread  209 4
before A, thread  209 4
after A, thread  209 5
before B, thread  209 5
after B, thread  209 6
before A, thread  209 6
after A, thread  209 7
before B, thread  209 7
after B, thread  209 8
before A, thread  209 8
after A, thread  209 9
before B, thread  209 9
after B, thread  209 10
before A, thread  209 10
after A, thread  209 11
before B, thread  209 11
after B, thread  209 12
209  done
[[1. 1.]]
before A, thread  169 0
after A, thread  169 1
before B, thread  169 1
after B, thread  169 2
before A, thread  169 2
after A, thread  169 3
before B, thread  169 3
after B, thread  169 4
before A, thread  169 4
after A, thread  169 5
before B, thread  169 5
after B, thread  169 6
before A, thread  169 6
after A, thread  169 7
before B, thread  169 7
after B, thread  169 8
before A, thread  169 8
after A, thread  169 9
before B, thread  169 9
after B, thread  169 10
before A, thread  169 10
after A, thread  169 11
before B, thread  169 11
after B, thread  169 12
169  done
[[1. 1.]]
before A, thread  154 0
after A, thread  154 1
before B, thread  154 1
after B, thread  154 2
before A, thread  154 2
after A, thread  154 3
before B, thread  154 3
after B, thread  154 4
before A, thread  154 4
after A, thread  154 5
before B, thread  154 5
after B, thread  154 6
before A, thread  154 6
after A, thread  154 7
before B, thread  154 7
after B, thread  154 8
before A, thread  154 8
after A, thread  154 9
before B, thread  154 9
after B, thread  154 10
before A, thread  154 10
after A, thread  154 11
before B, thread  154 11
after B, thread  154 12
154  done
[[1. 1.]]
before A, thread  204 0
after A, thread  204 1
before B, thread  204 1
after B, thread  204 2
before A, thread  204 2
after A, thread  204 3
before B, thread  204 3
after B, thread  204 4
before A, thread  204 4
after A, thread  204 5
before B, thread  204 5
after B, thread  204 6
before A, thread  204 6
after A, thread  204 7
before B, thread  204 7
after B, thread  204 8
before A, thread  204 8
after A, thread  204 9
before B, thread  204 9
after B, thread  204 10
before A, thread  204 10
after A, thread  204 11
before B, thread  204 11
after B, thread  204 12
204  done
[[1. 1.]]
before A, thread  217 0
after A, thread  217 1
before B, thread  217 1
after B, thread  217 2
before A, thread  217 2
after A, thread  217 3
before B, thread  217 3
after B, thread  217 4
before A, thread  217 4
after A, thread  217 5
before B, thread  217 5
after B, thread  217 6
before A, thread  217 6
after A, thread  217 7
before B, thread  217 7
after B, thread  217 8
before A, thread  217 8
after A, thread  217 9
before B, thread  217 9
after B, thread  217 10
before A, thread  217 10
after A, thread  217 11
before B, thread  217 11
after B, thread  217 12
217  done
[[1. 1.]]
before A, thread  120 0
after A, thread  120 1
before B, thread  120 1
after B, thread  120 2
before A, thread  120 2
after A, thread  120 3
before B, thread  120 3
after B, thread  120 4
before A, thread  120 4
after A, thread  120 5
before B, thread  120 5
after B, thread  120 6
before A, thread  120 6
after A, thread  120 7
before B, thread  120 7
after B, thread  120 8
before A, thread  120 8
after A, thread  120 9
before B, thread  120 9
after B, thread  120 10
before A, thread  120 10
after A, thread  120 11
before B, thread  120 11
after B, thread  120 12
120  done
[[1. 1.]]
before A, thread  53 0
after A, thread  53 1
before B, thread  53 1
after B, thread  53 2
before A, thread  53 2
after A, thread  53 3
before B, thread  53 3
after B, thread  53 4
before A, thread  53 4
after A, thread  53 5
before B, thread  53 5
after B, thread  53 6
before A, thread  53 6
after A, thread  53 7
before B, thread  53 7
after B, thread  53 8
before A, thread  53 8
after A, thread  53 9
before B, thread  53 9
after B, thread  53 10
before A, thread  53 10
after A, thread  53 11
before B, thread  53 11
after B, thread  53 12
53  done
[[1. 1.]]
before A, thread  62 0
after A, thread  62 1
before B, thread  62 1
after B, thread  62 2
before A, thread  62 2
after A, thread  62 3
before B, thread  62 3
after B, thread  62 4
before A, thread  62 4
after A, thread  62 5
before B, thread  62 5
after B, thread  62 6
before A, thread  62 6
after A, thread  62 7
before B, thread  62 7
after B, thread  62 8
before A, thread  62 8
after A, thread  62 9
before B, thread  62 9
after B, thread  62 10
before A, thread  62 10
after A, thread  62 11
before B, thread  62 11
after B, thread  62 12
62  done
[[1. 1.]]
before A, thread  203 0
after A, thread  203 1
before B, thread  203 1
after B, thread  203 2
before A, thread  203 2
after A, thread  203 3
before B, thread  203 3
after B, thread  203 4
before A, thread  203 4
after A, thread  203 5
before B, thread  203 5
after B, thread  203 6
before A, thread  203 6
after A, thread  203 7
before B, thread  203 7
after B, thread  203 8
before A, thread  203 8
after A, thread  203 9
before B, thread  203 9
after B, thread  203 10
before A, thread  203 10
after A, thread  203 11
before B, thread  203 11
after B, thread  203 12
203  done
[[1. 1.]]
before A, thread  97 0
after A, thread  97 1
before B, thread  97 1
after B, thread  97 2
before A, thread  97 2
after A, thread  97 3
before B, thread  97 3
after B, thread  97 4
before A, thread  97 4
after A, thread  97 5
before B, thread  97 5
after B, thread  97 6
before A, thread  97 6
after A, thread  97 7
before B, thread  97 7
after B, thread  97 8
before A, thread  97 8
after A, thread  97 9
before B, thread  97 9
after B, thread  97 10
before A, thread  97 10
after A, thread  97 11
before B, thread  97 11
after B, thread  97 12
97  done
[[1. 1.]]
before A, thread  95 0
after A, thread  95 1
before B, thread  95 1
after B, thread  95 2
before A, thread  95 2
after A, thread  95 3
before B, thread  95 3
after B, thread  95 4
before A, thread  95 4
after A, thread  95 5
before B, thread  95 5
after B, thread  95 6
before A, thread  95 6
after A, thread  95 7
before B, thread  95 7
after B, thread  95 8
before A, thread  95 8
after A, thread  95 9
before B, thread  95 9
after B, thread  95 10
before A, thread  95 10
after A, thread  95 11
before B, thread  95 11
after B, thread  95 12
95  done
[[1. 1.]]
before A, thread  237 0
after A, thread  237 1
before B, thread  237 1
after B, thread  237 2
before A, thread  237 2
after A, thread  237 3
before B, thread  237 3
after B, thread  237 4
before A, thread  237 4
after A, thread  237 5
before B, thread  237 5
after B, thread  237 6
before A, thread  237 6
after A, thread  237 7
before B, thread  237 7
after B, thread  237 8
before A, thread  237 8
after A, thread  237 9
before B, thread  237 9
after B, thread  237 10
before A, thread  237 10
after A, thread  237 11
before B, thread  237 11
after B, thread  237 12
237  done
[[1. 1.]]
before A, thread  153 0
after A, thread  153 1
before B, thread  153 1
after B, thread  153 2
before A, thread  153 2
after A, thread  153 3
before B, thread  153 3
after B, thread  153 4
before A, thread  153 4
after A, thread  153 5
before B, thread  153 5
after B, thread  153 6
before A, thread  153 6
after A, thread  153 7
before B, thread  153 7
after B, thread  153 8
before A, thread  153 8
after A, thread  153 9
before B, thread  153 9
after B, thread  153 10
before A, thread  153 10
after A, thread  153 11
before B, thread  153 11
after B, thread  153 12
153  done
[[1. 1.]]
before A, thread  185 0
after A, thread  185 1
before B, thread  185 1
after B, thread  185 2
before A, thread  185 2
after A, thread  185 3
before B, thread  185 3
after B, thread  185 4
before A, thread  185 4
after A, thread  185 5
before B, thread  185 5
after B, thread  185 6
before A, thread  185 6
after A, thread  185 7
before B, thread  185 7
after B, thread  185 8
before A, thread  185 8
after A, thread  185 9
before B, thread  185 9
after B, thread  185 10
before A, thread  185 10
after A, thread  185 11
before B, thread  185 11
after B, thread  185 12
185  done
[[1. 1.]]
before A, thread  190 0
after A, thread  190 1
before B, thread  190 1
after B, thread  190 2
before A, thread  190 2
after A, thread  190 3
before B, thread  190 3
after B, thread  190 4
before A, thread  190 4
after A, thread  190 5
before B, thread  190 5
after B, thread  190 6
before A, thread  190 6
after A, thread  190 7
before B, thread  190 7
after B, thread  190 8
before A, thread  190 8
after A, thread  190 9
before B, thread  190 9
after B, thread  190 10
before A, thread  190 10
after A, thread  190 11
before B, thread  190 11
after B, thread  190 12
190  done
[[1. 1.]]
before A, thread  234 0
after A, thread  234 1
before B, thread  234 1
after B, thread  234 2
before A, thread  234 2
after A, thread  234 3
before B, thread  234 3
after B, thread  234 4
before A, thread  234 4
after A, thread  234 5
before B, thread  234 5
after B, thread  234 6
before A, thread  234 6
after A, thread  234 7
before B, thread  234 7
after B, thread  234 8
before A, thread  234 8
after A, thread  234 9
before B, thread  234 9
after B, thread  234 10
before A, thread  234 10
after A, thread  234 11
before B, thread  234 11
after B, thread  234 12
234  done
[[1. 1.]]
before A, thread  188 0
after A, thread  188 1
before B, thread  188 1
after B, thread  188 2
before A, thread  188 2
after A, thread  188 3
before B, thread  188 3
after B, thread  188 4
before A, thread  188 4
after A, thread  188 5
before B, thread  188 5
after B, thread  188 6
before A, thread  188 6
after A, thread  188 7
before B, thread  188 7
after B, thread  188 8
before A, thread  188 8
after A, thread  188 9
before B, thread  188 9
after B, thread  188 10
before A, thread  188 10
after A, thread  188 11
before B, thread  188 11
after B, thread  188 12
188  done
[[1. 1.]]
before A, thread  194 0
after A, thread  194 1
before B, thread  194 1
after B, thread  194 2
before A, thread  194 2
after A, thread  194 3
before B, thread  194 3
after B, thread  194 4
before A, thread  194 4
after A, thread  194 5
before B, thread  194 5
after B, thread  194 6
before A, thread  194 6
after A, thread  194 7
before B, thread  194 7
after B, thread  194 8
before A, thread  194 8
after A, thread  194 9
before B, thread  194 9
after B, thread  194 10
before A, thread  194 10
after A, thread  194 11
before B, thread  194 11
after B, thread  194 12
194  done
[[1. 1.]]
before A, thread  222 0
after A, thread  222 1
before B, thread  222 1
after B, thread  222 2
before A, thread  222 2
after A, thread  222 3
before B, thread  222 3
after B, thread  222 4
before A, thread  222 4
after A, thread  222 5
before B, thread  222 5
after B, thread  222 6
before A, thread  222 6
after A, thread  222 7
before B, thread  222 7
after B, thread  222 8
before A, thread  222 8
after A, thread  222 9
before B, thread  222 9
after B, thread  222 10
before A, thread  222 10
after A, thread  222 11
before B, thread  222 11
after B, thread  222 12
222  done
[[1. 1.]]
before A, thread  28 0
after A, thread  28 1
before B, thread  28 1
after B, thread  28 2
before A, thread  28 2
after A, thread  28 3
before B, thread  28 3
after B, thread  28 4
before A, thread  28 4
after A, thread  28 5
before B, thread  28 5
after B, thread  28 6
before A, thread  28 6
after A, thread  28 7
before B, thread  28 7
after B, thread  28 8
before A, thread  28 8
after A, thread  28 9
before B, thread  28 9
after B, thread  28 10
before A, thread  28 10
after A, thread  28 11
before B, thread  28 11
after B, thread  28 12
28  done
[[1. 1.]]
before A, thread  96 0
after A, thread  96 1
before B, thread  96 1
after B, thread  96 2
before A, thread  96 2
after A, thread  96 3
before B, thread  96 3
after B, thread  96 4
before A, thread  96 4
after A, thread  96 5
before B, thread  96 5
after B, thread  96 6
before A, thread  96 6
after A, thread  96 7
before B, thread  96 7
after B, thread  96 8
before A, thread  96 8
after A, thread  96 9
before B, thread  96 9
after B, thread  96 10
before A, thread  96 10
after A, thread  96 11
before B, thread  96 11
after B, thread  96 12
96  done
[[1. 1.]]
before A, thread  42 0
after A, thread  42 1
before B, thread  42 1
after B, thread  42 2
before A, thread  42 2
after A, thread  42 3
before B, thread  42 3
after B, thread  42 4
before A, thread  42 4
after A, thread  42 5
before B, thread  42 5
after B, thread  42 6
before A, thread  42 6
after A, thread  42 7
before B, thread  42 7
after B, thread  42 8
before A, thread  42 8
after A, thread  42 9
before B, thread  42 9
after B, thread  42 10
before A, thread  42 10
after A, thread  42 11
before B, thread  42 11
after B, thread  42 12
42  done
[[1. 1.]]
before A, thread  50 0
after A, thread  50 1
before B, thread  50 1
after B, thread  50 2
before A, thread  50 2
after A, thread  50 3
before B, thread  50 3
after B, thread  50 4
before A, thread  50 4
after A, thread  50 5
before B, thread  50 5
after B, thread  50 6
before A, thread  50 6
after A, thread  50 7
before B, thread  50 7
after B, thread  50 8
before A, thread  50 8
after A, thread  50 9
before B, thread  50 9
after B, thread  50 10
before A, thread  50 10
after A, thread  50 11
before B, thread  50 11
after B, thread  50 12
50  done
[[1. 1.]]
before A, thread  99 0
after A, thread  99 1
before B, thread  99 1
after B, thread  99 2
before A, thread  99 2
after A, thread  99 3
before B, thread  99 3
after B, thread  99 4
before A, thread  99 4
after A, thread  99 5
before B, thread  99 5
after B, thread  99 6
before A, thread  99 6
after A, thread  99 7
before B, thread  99 7
after B, thread  99 8
before A, thread  99 8
after A, thread  99 9
before B, thread  99 9
after B, thread  99 10
before A, thread  99 10
after A, thread  99 11
before B, thread  99 11
after B, thread  99 12
99  done
[[1. 1.]]
before A, thread  57 0
after A, thread  57 1
before B, thread  57 1
after B, thread  57 2
before A, thread  57 2
after A, thread  57 3
before B, thread  57 3
after B, thread  57 4
before A, thread  57 4
after A, thread  57 5
before B, thread  57 5
after B, thread  57 6
before A, thread  57 6
after A, thread  57 7
before B, thread  57 7
after B, thread  57 8
before A, thread  57 8
after A, thread  57 9
before B, thread  57 9
after B, thread  57 10
before A, thread  57 10
after A, thread  57 11
before B, thread  57 11
after B, thread  57 12
57  done
[[1. 1.]]
before A, thread  250 0
after A, thread  250 1
before B, thread  250 1
after B, thread  250 2
before A, thread  250 2
after A, thread  250 3
before B, thread  250 3
after B, thread  250 4
before A, thread  250 4
after A, thread  250 5
before B, thread  250 5
after B, thread  250 6
before A, thread  250 6
after A, thread  250 7
before B, thread  250 7
after B, thread  250 8
before A, thread  250 8
after A, thread  250 9
before B, thread  250 9
after B, thread  250 10
before A, thread  250 10
after A, thread  250 11
before B, thread  250 11
after B, thread  250 12
250  done
[[1. 1.]]
before A, thread  126 0
after A, thread  126 1
before B, thread  126 1
after B, thread  126 2
before A, thread  126 2
after A, thread  126 3
before B, thread  126 3
after B, thread  126 4
before A, thread  126 4
after A, thread  126 5
before B, thread  126 5
after B, thread  126 6
before A, thread  126 6
after A, thread  126 7
before B, thread  126 7
after B, thread  126 8
before A, thread  126 8
after A, thread  126 9
before B, thread  126 9
after B, thread  126 10
before A, thread  126 10
after A, thread  126 11
before B, thread  126 11
after B, thread  126 12
126  done
[[1. 1.]]
before A, thread  171 0
after A, thread  171 1
before B, thread  171 1
after B, thread  171 2
before A, thread  171 2
after A, thread  171 3
before B, thread  171 3
after B, thread  171 4
before A, thread  171 4
after A, thread  171 5
before B, thread  171 5
after B, thread  171 6
before A, thread  171 6
after A, thread  171 7
before B, thread  171 7
after B, thread  171 8
before A, thread  171 8
after A, thread  171 9
before B, thread  171 9
after B, thread  171 10
before A, thread  171 10
after A, thread  171 11
before B, thread  171 11
after B, thread  171 12
171  done
[[1. 1.]]
before A, thread  34 0
after A, thread  34 1
before B, thread  34 1
after B, thread  34 2
before A, thread  34 2
after A, thread  34 3
before B, thread  34 3
after B, thread  34 4
before A, thread  34 4
after A, thread  34 5
before B, thread  34 5
after B, thread  34 6
before A, thread  34 6
after A, thread  34 7
before B, thread  34 7
after B, thread  34 8
before A, thread  34 8
after A, thread  34 9
before B, thread  34 9
after B, thread  34 10
before A, thread  34 10
after A, thread  34 11
before B, thread  34 11
after B, thread  34 12
34  done
[[1. 1.]]
before A, thread  225 0
after A, thread  225 1
before B, thread  225 1
after B, thread  225 2
before A, thread  225 2
after A, thread  225 3
before B, thread  225 3
after B, thread  225 4
before A, thread  225 4
after A, thread  225 5
before B, thread  225 5
after B, thread  225 6
before A, thread  225 6
after A, thread  225 7
before B, thread  225 7
after B, thread  225 8
before A, thread  225 8
after A, thread  225 9
before B, thread  225 9
after B, thread  225 10
before A, thread  225 10
after A, thread  225 11
before B, thread  225 11
after B, thread  225 12
225  done
[[1. 1.]]
before A, thread  133 0
after A, thread  133 1
before B, thread  133 1
after B, thread  133 2
before A, thread  133 2
after A, thread  133 3
before B, thread  133 3
after B, thread  133 4
before A, thread  133 4
after A, thread  133 5
before B, thread  133 5
after B, thread  133 6
before A, thread  133 6
after A, thread  133 7
before B, thread  133 7
after B, thread  133 8
before A, thread  133 8
after A, thread  133 9
before B, thread  133 9
after B, thread  133 10
before A, thread  133 10
after A, thread  133 11
before B, thread  133 11
after B, thread  133 12
133  done
[[1. 1.]]
before A, thread  175 0
after A, thread  175 1
before B, thread  175 1
after B, thread  175 2
before A, thread  175 2
after A, thread  175 3
before B, thread  175 3
after B, thread  175 4
before A, thread  175 4
after A, thread  175 5
before B, thread  175 5
after B, thread  175 6
before A, thread  175 6
after A, thread  175 7
before B, thread  175 7
after B, thread  175 8
before A, thread  175 8
after A, thread  175 9
before B, thread  175 9
after B, thread  175 10
before A, thread  175 10
after A, thread  175 11
before B, thread  175 11
after B, thread  175 12
175  done
[[1. 1.]]
before A, thread  6 0
after A, thread  6 1
before B, thread  6 1
after B, thread  6 2
before A, thread  6 2
after A, thread  6 3
before B, thread  6 3
after B, thread  6 4
before A, thread  6 4
after A, thread  6 5
before B, thread  6 5
after B, thread  6 6
before A, thread  6 6
after A, thread  6 7
before B, thread  6 7
after B, thread  6 8
before A, thread  6 8
after A, thread  6 9
before B, thread  6 9
after B, thread  6 10
before A, thread  6 10
after A, thread  6 11
before B, thread  6 11
after B, thread  6 12
6  done
[[1. 1.]]
before A, thread  211 0
after A, thread  211 1
before B, thread  211 1
after B, thread  211 2
before A, thread  211 2
after A, thread  211 3
before B, thread  211 3
after B, thread  211 4
before A, thread  211 4
after A, thread  211 5
before B, thread  211 5
after B, thread  211 6
before A, thread  211 6
after A, thread  211 7
before B, thread  211 7
after B, thread  211 8
before A, thread  211 8
after A, thread  211 9
before B, thread  211 9
after B, thread  211 10
before A, thread  211 10
after A, thread  211 11
before B, thread  211 11
after B, thread  211 12
211  done
[[1. 1.]]
before A, thread  196 0
after A, thread  196 1
before B, thread  196 1
after B, thread  196 2
before A, thread  196 2
after A, thread  196 3
before B, thread  196 3
after B, thread  196 4
before A, thread  196 4
after A, thread  196 5
before B, thread  196 5
after B, thread  196 6
before A, thread  196 6
after A, thread  196 7
before B, thread  196 7
after B, thread  196 8
before A, thread  196 8
after A, thread  196 9
before B, thread  196 9
after B, thread  196 10
before A, thread  196 10
after A, thread  196 11
before B, thread  196 11
after B, thread  196 12
196  done
[[1. 1.]]
before A, thread  186 0
after A, thread  186 1
before B, thread  186 1
after B, thread  186 2
before A, thread  186 2
after A, thread  186 3
before B, thread  186 3
after B, thread  186 4
before A, thread  186 4
after A, thread  186 5
before B, thread  186 5
after B, thread  186 6
before A, thread  186 6
after A, thread  186 7
before B, thread  186 7
after B, thread  186 8
before A, thread  186 8
after A, thread  186 9
before B, thread  186 9
after B, thread  186 10
before A, thread  186 10
after A, thread  186 11
before B, thread  186 11
after B, thread  186 12
186  done
[[1. 1.]]
before A, thread  236 0
after A, thread  236 1
before B, thread  236 1
after B, thread  236 2
before A, thread  236 2
after A, thread  236 3
before B, thread  236 3
after B, thread  236 4
before A, thread  236 4
after A, thread  236 5
before B, thread  236 5
after B, thread  236 6
before A, thread  236 6
after A, thread  236 7
before B, thread  236 7
after B, thread  236 8
before A, thread  236 8
after A, thread  236 9
before B, thread  236 9
after B, thread  236 10
before A, thread  236 10
after A, thread  236 11
before B, thread  236 11
after B, thread  236 12
236  done
[[1. 1.]]
before A, thread  38 0
after A, thread  38 1
before B, thread  38 1
after B, thread  38 2
before A, thread  38 2
after A, thread  38 3
before B, thread  38 3
after B, thread  38 4
before A, thread  38 4
after A, thread  38 5
before B, thread  38 5
after B, thread  38 6
before A, thread  38 6
after A, thread  38 7
before B, thread  38 7
after B, thread  38 8
before A, thread  38 8
after A, thread  38 9
before B, thread  38 9
after B, thread  38 10
before A, thread  38 10
after A, thread  38 11
before B, thread  38 11
after B, thread  38 12
38  done
[[1. 1.]]
before A, thread  166 0
after A, thread  166 1
before B, thread  166 1
after B, thread  166 2
before A, thread  166 2
after A, thread  166 3
before B, thread  166 3
after B, thread  166 4
before A, thread  166 4
after A, thread  166 5
before B, thread  166 5
after B, thread  166 6
before A, thread  166 6
after A, thread  166 7
before B, thread  166 7
after B, thread  166 8
before A, thread  166 8
after A, thread  166 9
before B, thread  166 9
after B, thread  166 10
before A, thread  166 10
after A, thread  166 11
before B, thread  166 11
after B, thread  166 12
166  done
[[1. 1.]]
before A, thread  151 0
after A, thread  151 1
before B, thread  151 1
after B, thread  151 2
before A, thread  151 2
after A, thread  151 3
before B, thread  151 3
after B, thread  151 4
before A, thread  151 4
after A, thread  151 5
before B, thread  151 5
after B, thread  151 6
before A, thread  151 6
after A, thread  151 7
before B, thread  151 7
after B, thread  151 8
before A, thread  151 8
after A, thread  151 9
before B, thread  151 9
after B, thread  151 10
before A, thread  151 10
after A, thread  151 11
before B, thread  151 11
after B, thread  151 12
151  done
[[1. 1.]]
before A, thread  206 0
after A, thread  206 1
before B, thread  206 1
after B, thread  206 2
before A, thread  206 2
after A, thread  206 3
before B, thread  206 3
after B, thread  206 4
before A, thread  206 4
after A, thread  206 5
before B, thread  206 5
after B, thread  206 6
before A, thread  206 6
after A, thread  206 7
before B, thread  206 7
after B, thread  206 8
before A, thread  206 8
after A, thread  206 9
before B, thread  206 9
after B, thread  206 10
before A, thread  206 10
after A, thread  206 11
before B, thread  206 11
after B, thread  206 12
206  done
[[1. 1.]]
before A, thread  242 0
after A, thread  242 1
before B, thread  242 1
after B, thread  242 2
before A, thread  242 2
after A, thread  242 3
before B, thread  242 3
after B, thread  242 4
before A, thread  242 4
after A, thread  242 5
before B, thread  242 5
after B, thread  242 6
before A, thread  242 6
after A, thread  242 7
before B, thread  242 7
after B, thread  242 8
before A, thread  242 8
after A, thread  242 9
before B, thread  242 9
after B, thread  242 10
before A, thread  242 10
after A, thread  242 11
before B, thread  242 11
after B, thread  242 12
242  done
[[1. 1.]]
before A, thread  109 0
after A, thread  109 1
before B, thread  109 1
after B, thread  109 2
before A, thread  109 2
after A, thread  109 3
before B, thread  109 3
after B, thread  109 4
before A, thread  109 4
after A, thread  109 5
before B, thread  109 5
after B, thread  109 6
before A, thread  109 6
after A, thread  109 7
before B, thread  109 7
after B, thread  109 8
before A, thread  109 8
after A, thread  109 9
before B, thread  109 9
after B, thread  109 10
before A, thread  109 10
after A, thread  109 11
before B, thread  109 11
after B, thread  109 12
109  done
[[1. 1.]]
before A, thread  122 0
after A, thread  122 1
before B, thread  122 1
after B, thread  122 2
before A, thread  122 2
after A, thread  122 3
before B, thread  122 3
after B, thread  122 4
before A, thread  122 4
after A, thread  122 5
before B, thread  122 5
after B, thread  122 6
before A, thread  122 6
after A, thread  122 7
before B, thread  122 7
after B, thread  122 8
before A, thread  122 8
after A, thread  122 9
before B, thread  122 9
after B, thread  122 10
before A, thread  122 10
after A, thread  122 11
before B, thread  122 11
after B, thread  122 12
122  done
[[1. 1.]]
before A, thread  157 0
after A, thread  157 1
before B, thread  157 1
after B, thread  157 2
before A, thread  157 2
after A, thread  157 3
before B, thread  157 3
after B, thread  157 4
before A, thread  157 4
after A, thread  157 5
before B, thread  157 5
after B, thread  157 6
before A, thread  157 6
after A, thread  157 7
before B, thread  157 7
after B, thread  157 8
before A, thread  157 8
after A, thread  157 9
before B, thread  157 9
after B, thread  157 10
before A, thread  157 10
after A, thread  157 11
before B, thread  157 11
after B, thread  157 12
157  done
[[1. 1.]]
before A, thread  239 0
after A, thread  239 1
before B, thread  239 1
after B, thread  239 2
before A, thread  239 2
after A, thread  239 3
before B, thread  239 3
after B, thread  239 4
before A, thread  239 4
after A, thread  239 5
before B, thread  239 5
after B, thread  239 6
before A, thread  239 6
after A, thread  239 7
before B, thread  239 7
after B, thread  239 8
before A, thread  239 8
after A, thread  239 9
before B, thread  239 9
after B, thread  239 10
before A, thread  239 10
after A, thread  239 11
before B, thread  239 11
after B, thread  239 12
239  done
[[1. 1.]]
before A, thread  233 0
after A, thread  233 1
before B, thread  233 1
after B, thread  233 2
before A, thread  233 2
after A, thread  233 3
before B, thread  233 3
after B, thread  233 4
before A, thread  233 4
after A, thread  233 5
before B, thread  233 5
after B, thread  233 6
before A, thread  233 6
after A, thread  233 7
before B, thread  233 7
after B, thread  233 8
before A, thread  233 8
after A, thread  233 9
before B, thread  233 9
after B, thread  233 10
before A, thread  233 10
after A, thread  233 11
before B, thread  233 11
after B, thread  233 12
233  done
[[1. 1.]]
before A, thread  191 0
after A, thread  191 1
before B, thread  191 1
after B, thread  191 2
before A, thread  191 2
after A, thread  191 3
before B, thread  191 3
after B, thread  191 4
before A, thread  191 4
after A, thread  191 5
before B, thread  191 5
after B, thread  191 6
before A, thread  191 6
after A, thread  191 7
before B, thread  191 7
after B, thread  191 8
before A, thread  191 8
after A, thread  191 9
before B, thread  191 9
after B, thread  191 10
before A, thread  191 10
after A, thread  191 11
before B, thread  191 11
after B, thread  191 12
191  done
[[1. 1.]]
before A, thread  221 0
after A, thread  221 1
before B, thread  221 1
after B, thread  221 2
before A, thread  221 2
after A, thread  221 3
before B, thread  221 3
after B, thread  221 4
before A, thread  221 4
after A, thread  221 5
before B, thread  221 5
after B, thread  221 6
before A, thread  221 6
after A, thread  221 7
before B, thread  221 7
after B, thread  221 8
before A, thread  221 8
after A, thread  221 9
before B, thread  221 9
after B, thread  221 10
before A, thread  221 10
after A, thread  221 11
before B, thread  221 11
after B, thread  221 12
221  done
[[1. 1.]]
before A, thread  213 0
after A, thread  213 1
before B, thread  213 1
after B, thread  213 2
before A, thread  213 2
after A, thread  213 3
before B, thread  213 3
after B, thread  213 4
before A, thread  213 4
after A, thread  213 5
before B, thread  213 5
after B, thread  213 6
before A, thread  213 6
after A, thread  213 7
before B, thread  213 7
after B, thread  213 8
before A, thread  213 8
after A, thread  213 9
before B, thread  213 9
after B, thread  213 10
before A, thread  213 10
after A, thread  213 11
before B, thread  213 11
after B, thread  213 12
213  done
[[1. 1.]]
before A, thread  216 0
after A, thread  216 1
before B, thread  216 1
after B, thread  216 2
before A, thread  216 2
after A, thread  216 3
before B, thread  216 3
after B, thread  216 4
before A, thread  216 4
after A, thread  216 5
before B, thread  216 5
after B, thread  216 6
before A, thread  216 6
after A, thread  216 7
before B, thread  216 7
after B, thread  216 8
before A, thread  216 8
after A, thread  216 9
before B, thread  216 9
after B, thread  216 10
before A, thread  216 10
after A, thread  216 11
before B, thread  216 11
after B, thread  216 12
216  done
[[1. 1.]]
before A, thread  212 0
after A, thread  212 1
before B, thread  212 1
after B, thread  212 2
before A, thread  212 2
after A, thread  212 3
before B, thread  212 3
after B, thread  212 4
before A, thread  212 4
after A, thread  212 5
before B, thread  212 5
after B, thread  212 6
before A, thread  212 6
after A, thread  212 7
before B, thread  212 7
after B, thread  212 8
before A, thread  212 8
after A, thread  212 9
before B, thread  212 9
after B, thread  212 10
before A, thread  212 10
after A, thread  212 11
before B, thread  212 11
after B, thread  212 12
212  done
[[1. 1.]]
before A, thread  159 0
after A, thread  159 1
before B, thread  159 1
after B, thread  159 2
before A, thread  159 2
after A, thread  159 3
before B, thread  159 3
after B, thread  159 4
before A, thread  159 4
after A, thread  159 5
before B, thread  159 5
after B, thread  159 6
before A, thread  159 6
after A, thread  159 7
before B, thread  159 7
after B, thread  159 8
before A, thread  159 8
after A, thread  159 9
before B, thread  159 9
after B, thread  159 10
before A, thread  159 10
after A, thread  159 11
before B, thread  159 11
after B, thread  159 12
159  done
[[1. 1.]]
before A, thread  176 0
after A, thread  176 1
before B, thread  176 1
after B, thread  176 2
before A, thread  176 2
after A, thread  176 3
before B, thread  176 3
after B, thread  176 4
before A, thread  176 4
after A, thread  176 5
before B, thread  176 5
after B, thread  176 6
before A, thread  176 6
after A, thread  176 7
before B, thread  176 7
after B, thread  176 8
before A, thread  176 8
after A, thread  176 9
before B, thread  176 9
after B, thread  176 10
before A, thread  176 10
after A, thread  176 11
before B, thread  176 11
after B, thread  176 12
176  done
[[1. 1.]]
before A, thread  106 0
after A, thread  106 1
before B, thread  106 1
after B, thread  106 2
before A, thread  106 2
after A, thread  106 3
before B, thread  106 3
after B, thread  106 4
before A, thread  106 4
after A, thread  106 5
before B, thread  106 5
after B, thread  106 6
before A, thread  106 6
after A, thread  106 7
before B, thread  106 7
after B, thread  106 8
before A, thread  106 8
after A, thread  106 9
before B, thread  106 9
after B, thread  106 10
before A, thread  106 10
after A, thread  106 11
before B, thread  106 11
after B, thread  106 12
106  done
[[1. 1.]]
before A, thread  152 0
after A, thread  152 1
before B, thread  152 1
after B, thread  152 2
before A, thread  152 2
after A, thread  152 3
before B, thread  152 3
after B, thread  152 4
before A, thread  152 4
after A, thread  152 5
before B, thread  152 5
after B, thread  152 6
before A, thread  152 6
after A, thread  152 7
before B, thread  152 7
after B, thread  152 8
before A, thread  152 8
after A, thread  152 9
before B, thread  152 9
after B, thread  152 10
before A, thread  152 10
after A, thread  152 11
before B, thread  152 11
after B, thread  152 12
152  done
[[1. 1.]]
before A, thread  64 0
after A, thread  64 1
before B, thread  64 1
after B, thread  64 2
before A, thread  64 2
after A, thread  64 3
before B, thread  64 3
after B, thread  64 4
before A, thread  64 4
after A, thread  64 5
before B, thread  64 5
after B, thread  64 6
before A, thread  64 6
after A, thread  64 7
before B, thread  64 7
after B, thread  64 8
before A, thread  64 8
after A, thread  64 9
before B, thread  64 9
after B, thread  64 10
before A, thread  64 10
after A, thread  64 11
before B, thread  64 11
after B, thread  64 12
64  done
[[1. 1.]]
before A, thread  137 0
after A, thread  137 1
before B, thread  137 1
after B, thread  137 2
before A, thread  137 2
after A, thread  137 3
before B, thread  137 3
after B, thread  137 4
before A, thread  137 4
after A, thread  137 5
before B, thread  137 5
after B, thread  137 6
before A, thread  137 6
after A, thread  137 7
before B, thread  137 7
after B, thread  137 8
before A, thread  137 8
after A, thread  137 9
before B, thread  137 9
after B, thread  137 10
before A, thread  137 10
after A, thread  137 11
before B, thread  137 11
after B, thread  137 12
137  done
[[1. 1.]]
before A, thread  60 0
after A, thread  60 1
before B, thread  60 1
after B, thread  60 2
before A, thread  60 2
after A, thread  60 3
before B, thread  60 3
after B, thread  60 4
before A, thread  60 4
after A, thread  60 5
before B, thread  60 5
after B, thread  60 6
before A, thread  60 6
after A, thread  60 7
before B, thread  60 7
after B, thread  60 8
before A, thread  60 8
after A, thread  60 9
before B, thread  60 9
after B, thread  60 10
before A, thread  60 10
after A, thread  60 11
before B, thread  60 11
after B, thread  60 12
60  done
[[1. 1.]]
before A, thread  149 0
after A, thread  149 1
before B, thread  149 1
after B, thread  149 2
before A, thread  149 2
after A, thread  149 3
before B, thread  149 3
after B, thread  149 4
before A, thread  149 4
after A, thread  149 5
before B, thread  149 5
after B, thread  149 6
before A, thread  149 6
after A, thread  149 7
before B, thread  149 7
after B, thread  149 8
before A, thread  149 8
after A, thread  149 9
before B, thread  149 9
after B, thread  149 10
before A, thread  149 10
after A, thread  149 11
before B, thread  149 11
after B, thread  149 12
149  done
[[1. 1.]]
before A, thread  124 0
after A, thread  124 1
before B, thread  124 1
after B, thread  124 2
before A, thread  124 2
after A, thread  124 3
before B, thread  124 3
after B, thread  124 4
before A, thread  124 4
after A, thread  124 5
before B, thread  124 5
after B, thread  124 6
before A, thread  124 6
after A, thread  124 7
before B, thread  124 7
after B, thread  124 8
before A, thread  124 8
after A, thread  124 9
before B, thread  124 9
after B, thread  124 10
before A, thread  124 10
after A, thread  124 11
before B, thread  124 11
after B, thread  124 12
124  done
[[1. 1.]]
before A, thread  94 0
after A, thread  94 1
before B, thread  94 1
after B, thread  94 2
before A, thread  94 2
after A, thread  94 3
before B, thread  94 3
after B, thread  94 4
before A, thread  94 4
after A, thread  94 5
before B, thread  94 5
after B, thread  94 6
before A, thread  94 6
after A, thread  94 7
before B, thread  94 7
after B, thread  94 8
before A, thread  94 8
after A, thread  94 9
before B, thread  94 9
after B, thread  94 10
before A, thread  94 10
after A, thread  94 11
before B, thread  94 11
after B, thread  94 12
94  done
[[1. 1.]]
before A, thread  123 0
after A, thread  123 1
before B, thread  123 1
after B, thread  123 2
before A, thread  123 2
after A, thread  123 3
before B, thread  123 3
after B, thread  123 4
before A, thread  123 4
after A, thread  123 5
before B, thread  123 5
after B, thread  123 6
before A, thread  123 6
after A, thread  123 7
before B, thread  123 7
after B, thread  123 8
before A, thread  123 8
after A, thread  123 9
before B, thread  123 9
after B, thread  123 10
before A, thread  123 10
after A, thread  123 11
before B, thread  123 11
after B, thread  123 12
123  done
[[1. 1.]]
before A, thread  235 0
after A, thread  235 1
before B, thread  235 1
after B, thread  235 2
before A, thread  235 2
after A, thread  235 3
before B, thread  235 3
after B, thread  235 4
before A, thread  235 4
after A, thread  235 5
before B, thread  235 5
after B, thread  235 6
before A, thread  235 6
after A, thread  235 7
before B, thread  235 7
after B, thread  235 8
before A, thread  235 8
after A, thread  235 9
before B, thread  235 9
after B, thread  235 10
before A, thread  235 10
after A, thread  235 11
before B, thread  235 11
after B, thread  235 12
235  done
[[1. 1.]]
before A, thread  145 0
after A, thread  145 1
before B, thread  145 1
after B, thread  145 2
before A, thread  145 2
after A, thread  145 3
before B, thread  145 3
after B, thread  145 4
before A, thread  145 4
after A, thread  145 5
before B, thread  145 5
after B, thread  145 6
before A, thread  145 6
after A, thread  145 7
before B, thread  145 7
after B, thread  145 8
before A, thread  145 8
after A, thread  145 9
before B, thread  145 9
after B, thread  145 10
before A, thread  145 10
after A, thread  145 11
before B, thread  145 11
after B, thread  145 12
145  done
[[1. 1.]]
before A, thread  189 0
after A, thread  189 1
before B, thread  189 1
after B, thread  189 2
before A, thread  189 2
after A, thread  189 3
before B, thread  189 3
after B, thread  189 4
before A, thread  189 4
after A, thread  189 5
before B, thread  189 5
after B, thread  189 6
before A, thread  189 6
after A, thread  189 7
before B, thread  189 7
after B, thread  189 8
before A, thread  189 8
after A, thread  189 9
before B, thread  189 9
after B, thread  189 10
before A, thread  189 10
after A, thread  189 11
before B, thread  189 11
after B, thread  189 12
189  done
[[1. 1.]]
before A, thread  200 0
after A, thread  200 1
before B, thread  200 1
after B, thread  200 2
before A, thread  200 2
after A, thread  200 3
before B, thread  200 3
after B, thread  200 4
before A, thread  200 4
after A, thread  200 5
before B, thread  200 5
after B, thread  200 6
before A, thread  200 6
after A, thread  200 7
before B, thread  200 7
after B, thread  200 8
before A, thread  200 8
after A, thread  200 9
before B, thread  200 9
after B, thread  200 10
before A, thread  200 10
after A, thread  200 11
before B, thread  200 11
after B, thread  200 12
200  done
[[1. 1.]]
before A, thread  249 0
after A, thread  249 1
before B, thread  249 1
after B, thread  249 2
before A, thread  249 2
after A, thread  249 3
before B, thread  249 3
after B, thread  249 4
before A, thread  249 4
after A, thread  249 5
before B, thread  249 5
after B, thread  249 6
before A, thread  249 6
after A, thread  249 7
before B, thread  249 7
after B, thread  249 8
before A, thread  249 8
after A, thread  249 9
before B, thread  249 9
after B, thread  249 10
before A, thread  249 10
after A, thread  249 11
before B, thread  249 11
after B, thread  249 12
249  done
[[1. 1.]]
before A, thread  224 0
after A, thread  224 1
before B, thread  224 1
after B, thread  224 2
before A, thread  224 2
after A, thread  224 3
before B, thread  224 3
after B, thread  224 4
before A, thread  224 4
after A, thread  224 5
before B, thread  224 5
after B, thread  224 6
before A, thread  224 6
after A, thread  224 7
before B, thread  224 7
after B, thread  224 8
before A, thread  224 8
after A, thread  224 9
before B, thread  224 9
after B, thread  224 10
before A, thread  224 10
after A, thread  224 11
before B, thread  224 11
after B, thread  224 12
224  done
[[1. 1.]]
before A, thread  177 0
after A, thread  177 1
before B, thread  177 1
after B, thread  177 2
before A, thread  177 2
after A, thread  177 3
before B, thread  177 3
after B, thread  177 4
before A, thread  177 4
after A, thread  177 5
before B, thread  177 5
after B, thread  177 6
before A, thread  177 6
after A, thread  177 7
before B, thread  177 7
after B, thread  177 8
before A, thread  177 8
after A, thread  177 9
before B, thread  177 9
after B, thread  177 10
before A, thread  177 10
after A, thread  177 11
before B, thread  177 11
after B, thread  177 12
177  done
[[1. 1.]]
before A, thread  214 0
after A, thread  214 1
before B, thread  214 1
after B, thread  214 2
before A, thread  214 2
after A, thread  214 3
before B, thread  214 3
after B, thread  214 4
before A, thread  214 4
after A, thread  214 5
before B, thread  214 5
after B, thread  214 6
before A, thread  214 6
after A, thread  214 7
before B, thread  214 7
after B, thread  214 8
before A, thread  214 8
after A, thread  214 9
before B, thread  214 9
after B, thread  214 10
before A, thread  214 10
after A, thread  214 11
before B, thread  214 11
after B, thread  214 12
214  done
[[1. 1.]]
before A, thread  232 0
after A, thread  232 1
before B, thread  232 1
after B, thread  232 2
before A, thread  232 2
after A, thread  232 3
before B, thread  232 3
after B, thread  232 4
before A, thread  232 4
after A, thread  232 5
before B, thread  232 5
after B, thread  232 6
before A, thread  232 6
after A, thread  232 7
before B, thread  232 7
after B, thread  232 8
before A, thread  232 8
after A, thread  232 9
before B, thread  232 9
after B, thread  232 10
before A, thread  232 10
after A, thread  232 11
before B, thread  232 11
after B, thread  232 12
232  done
[[1. 1.]]
before A, thread  72 0
after A, thread  72 1
before B, thread  72 1
after B, thread  72 2
before A, thread  72 2
after A, thread  72 3
before B, thread  72 3
after B, thread  72 4
before A, thread  72 4
after A, thread  72 5
before B, thread  72 5
after B, thread  72 6
before A, thread  72 6
after A, thread  72 7
before B, thread  72 7
after B, thread  72 8
before A, thread  72 8
after A, thread  72 9
before B, thread  72 9
after B, thread  72 10
before A, thread  72 10
after A, thread  72 11
before B, thread  72 11
after B, thread  72 12
72  done
[[1. 1.]]
before A, thread  220 0
after A, thread  220 1
before B, thread  220 1
after B, thread  220 2
before A, thread  220 2
after A, thread  220 3
before B, thread  220 3
after B, thread  220 4
before A, thread  220 4
after A, thread  220 5
before B, thread  220 5
after B, thread  220 6
before A, thread  220 6
after A, thread  220 7
before B, thread  220 7
after B, thread  220 8
before A, thread  220 8
after A, thread  220 9
before B, thread  220 9
after B, thread  220 10
before A, thread  220 10
after A, thread  220 11
before B, thread  220 11
after B, thread  220 12
220  done
[[1. 1.]]
before A, thread  202 0
after A, thread  202 1
before B, thread  202 1
after B, thread  202 2
before A, thread  202 2
after A, thread  202 3
before B, thread  202 3
after B, thread  202 4
before A, thread  202 4
after A, thread  202 5
before B, thread  202 5
after B, thread  202 6
before A, thread  202 6
after A, thread  202 7
before B, thread  202 7
after B, thread  202 8
before A, thread  202 8
after A, thread  202 9
before B, thread  202 9
after B, thread  202 10
before A, thread  202 10
after A, thread  202 11
before B, thread  202 11
after B, thread  202 12
202  done
[[1. 1.]]
before A, thread  207 0
after A, thread  207 1
before B, thread  207 1
after B, thread  207 2
before A, thread  207 2
after A, thread  207 3
before B, thread  207 3
after B, thread  207 4
before A, thread  207 4
after A, thread  207 5
before B, thread  207 5
after B, thread  207 6
before A, thread  207 6
after A, thread  207 7
before B, thread  207 7
after B, thread  207 8
before A, thread  207 8
after A, thread  207 9
before B, thread  207 9
after B, thread  207 10
before A, thread  207 10
after A, thread  207 11
before B, thread  207 11
after B, thread  207 12
207  done
[[1. 1.]]
before A, thread  243 0
after A, thread  243 1
before B, thread  243 1
after B, thread  243 2
before A, thread  243 2
after A, thread  243 3
before B, thread  243 3
after B, thread  243 4
before A, thread  243 4
after A, thread  243 5
before B, thread  243 5
after B, thread  243 6
before A, thread  243 6
after A, thread  243 7
before B, thread  243 7
after B, thread  243 8
before A, thread  243 8
after A, thread  243 9
before B, thread  243 9
after B, thread  243 10
before A, thread  243 10
after A, thread  243 11
before B, thread  243 11
after B, thread  243 12
243  done
[[1. 1.]]
before A, thread  115 0
after A, thread  115 1
before B, thread  115 1
after B, thread  115 2
before A, thread  115 2
after A, thread  115 3
before B, thread  115 3
after B, thread  115 4
before A, thread  115 4
after A, thread  115 5
before B, thread  115 5
after B, thread  115 6
before A, thread  115 6
after A, thread  115 7
before B, thread  115 7
after B, thread  115 8
before A, thread  115 8
after A, thread  115 9
before B, thread  115 9
after B, thread  115 10
before A, thread  115 10
after A, thread  115 11
before B, thread  115 11
after B, thread  115 12
115  done
[[1. 1.]]
before A, thread  167 0
after A, thread  167 1
before B, thread  167 1
after B, thread  167 2
before A, thread  167 2
after A, thread  167 3
before B, thread  167 3
after B, thread  167 4
before A, thread  167 4
after A, thread  167 5
before B, thread  167 5
after B, thread  167 6
before A, thread  167 6
after A, thread  167 7
before B, thread  167 7
after B, thread  167 8
before A, thread  167 8
after A, thread  167 9
before B, thread  167 9
after B, thread  167 10
before A, thread  167 10
after A, thread  167 11
before B, thread  167 11
after B, thread  167 12
167  done
[[1. 1.]]
before A, thread  195 0
after A, thread  195 1
before B, thread  195 1
after B, thread  195 2
before A, thread  195 2
after A, thread  195 3
before B, thread  195 3
after B, thread  195 4
before A, thread  195 4
after A, thread  195 5
before B, thread  195 5
after B, thread  195 6
before A, thread  195 6
after A, thread  195 7
before B, thread  195 7
after B, thread  195 8
before A, thread  195 8
after A, thread  195 9
before B, thread  195 9
after B, thread  195 10
before A, thread  195 10
after A, thread  195 11
before B, thread  195 11
after B, thread  195 12
195  done
[[1. 1.]]
before A, thread  215 0
after A, thread  215 1
before B, thread  215 1
after B, thread  215 2
before A, thread  215 2
after A, thread  215 3
before B, thread  215 3
after B, thread  215 4
before A, thread  215 4
after A, thread  215 5
before B, thread  215 5
after B, thread  215 6
before A, thread  215 6
after A, thread  215 7
before B, thread  215 7
after B, thread  215 8
before A, thread  215 8
after A, thread  215 9
before B, thread  215 9
after B, thread  215 10
before A, thread  215 10
after A, thread  215 11
before B, thread  215 11
after B, thread  215 12
215  done
[[1. 1.]]
before A, thread  228 0
after A, thread  228 1
before B, thread  228 1
after B, thread  228 2
before A, thread  228 2
after A, thread  228 3
before B, thread  228 3
after B, thread  228 4
before A, thread  228 4
after A, thread  228 5
before B, thread  228 5
after B, thread  228 6
before A, thread  228 6
after A, thread  228 7
before B, thread  228 7
after B, thread  228 8
before A, thread  228 8
after A, thread  228 9
before B, thread  228 9
after B, thread  228 10
before A, thread  228 10
after A, thread  228 11
before B, thread  228 11
after B, thread  228 12
228  done
[[1. 1.]]
before A, thread  178 0
after A, thread  178 1
before B, thread  178 1
after B, thread  178 2
before A, thread  178 2
after A, thread  178 3
before B, thread  178 3
after B, thread  178 4
before A, thread  178 4
after A, thread  178 5
before B, thread  178 5
after B, thread  178 6
before A, thread  178 6
after A, thread  178 7
before B, thread  178 7
after B, thread  178 8
before A, thread  178 8
after A, thread  178 9
before B, thread  178 9
after B, thread  178 10
before A, thread  178 10
after A, thread  178 11
before B, thread  178 11
after B, thread  178 12
178  done
[[1. 1.]]
before A, thread  226 0
after A, thread  226 1
before B, thread  226 1
after B, thread  226 2
before A, thread  226 2
after A, thread  226 3
before B, thread  226 3
after B, thread  226 4
before A, thread  226 4
after A, thread  226 5
before B, thread  226 5
after B, thread  226 6
before A, thread  226 6
after A, thread  226 7
before B, thread  226 7
after B, thread  226 8
before A, thread  226 8
after A, thread  226 9
before B, thread  226 9
after B, thread  226 10
before A, thread  226 10
after A, thread  226 11
before B, thread  226 11
after B, thread  226 12
226  done
[[1. 1.]]
before A, thread  231 0
after A, thread  231 1
before B, thread  231 1
after B, thread  231 2
before A, thread  231 2
after A, thread  231 3
before B, thread  231 3
after B, thread  231 4
before A, thread  231 4
after A, thread  231 5
before B, thread  231 5
after B, thread  231 6
before A, thread  231 6
after A, thread  231 7
before B, thread  231 7
after B, thread  231 8
before A, thread  231 8
after A, thread  231 9
before B, thread  231 9
after B, thread  231 10
before A, thread  231 10
after A, thread  231 11
before B, thread  231 11
after B, thread  231 12
231  done
[[1. 1.]]
before A, thread  219 0
after A, thread  219 1
before B, thread  219 1
after B, thread  219 2
before A, thread  219 2
after A, thread  219 3
before B, thread  219 3
after B, thread  219 4
before A, thread  219 4
after A, thread  219 5
before B, thread  219 5
after B, thread  219 6
before A, thread  219 6
after A, thread  219 7
before B, thread  219 7
after B, thread  219 8
before A, thread  219 8
after A, thread  219 9
before B, thread  219 9
after B, thread  219 10
before A, thread  219 10
after A, thread  219 11
before B, thread  219 11
after B, thread  219 12
219  done
[[1. 1.]]
before A, thread  125 0
after A, thread  125 1
before B, thread  125 1
after B, thread  125 2
before A, thread  125 2
after A, thread  125 3
before B, thread  125 3
after B, thread  125 4
before A, thread  125 4
after A, thread  125 5
before B, thread  125 5
after B, thread  125 6
before A, thread  125 6
after A, thread  125 7
before B, thread  125 7
after B, thread  125 8
before A, thread  125 8
after A, thread  125 9
before B, thread  125 9
after B, thread  125 10
before A, thread  125 10
after A, thread  125 11
before B, thread  125 11
after B, thread  125 12
125  done
[[1. 1.]]
before A, thread  205 0
after A, thread  205 1
before B, thread  205 1
after B, thread  205 2
before A, thread  205 2
after A, thread  205 3
before B, thread  205 3
after B, thread  205 4
before A, thread  205 4
after A, thread  205 5
before B, thread  205 5
after B, thread  205 6
before A, thread  205 6
after A, thread  205 7
before B, thread  205 7
after B, thread  205 8
before A, thread  205 8
after A, thread  205 9
before B, thread  205 9
after B, thread  205 10
before A, thread  205 10
after A, thread  205 11
before B, thread  205 11
after B, thread  205 12
205  done
[[1. 1.]]
before A, thread  230 0
after A, thread  230 1
before B, thread  230 1
after B, thread  230 2
before A, thread  230 2
after A, thread  230 3
before B, thread  230 3
after B, thread  230 4
before A, thread  230 4
after A, thread  230 5
before B, thread  230 5
after B, thread  230 6
before A, thread  230 6
after A, thread  230 7
before B, thread  230 7
after B, thread  230 8
before A, thread  230 8
after A, thread  230 9
before B, thread  230 9
after B, thread  230 10
before A, thread  230 10
after A, thread  230 11
before B, thread  230 11
after B, thread  230 12
230  done
[[1. 1.]]
before A, thread  240 0
after A, thread  240 1
before B, thread  240 1
after B, thread  240 2
before A, thread  240 2
after A, thread  240 3
before B, thread  240 3
after B, thread  240 4
before A, thread  240 4
after A, thread  240 5
before B, thread  240 5
after B, thread  240 6
before A, thread  240 6
after A, thread  240 7
before B, thread  240 7
after B, thread  240 8
before A, thread  240 8
after A, thread  240 9
before B, thread  240 9
after B, thread  240 10
before A, thread  240 10
after A, thread  240 11
before B, thread  240 11
after B, thread  240 12
240  done
Traceback (most recent call last):
  File "tf_process_mp.py", line 36, in <module>
    j.start()
  File "/home/mxxmhh/anaconda3/lib/python3.7/multiprocessing/process.py", line 112, in start
    self._popen = self._Popen(self)
  File "/home/mxxmhh/anaconda3/lib/python3.7/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/mxxmhh/anaconda3/lib/python3.7/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/mxxmhh/anaconda3/lib/python3.7/multiprocessing/popen_fork.py", line 20, in __init__
    self._launch(process_obj)
  File "/home/mxxmhh/anaconda3/lib/python3.7/multiprocessing/popen_fork.py", line 70, in _launch
    self.pid = os.fork()
BlockingIOError: [Errno 11] Resource temporarily unavailable
